{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AIR Project\n",
    "## Group 17\n",
    "\n",
    "We are using a dataset which includes non-fake as well as fake news (labeled dataset).\n",
    "https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and specific settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import ast\n",
    "import os.path\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryRecall, BinaryPrecision, BinaryAccuracy\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running models with cpu\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"running models with {}\".format(device))\n",
    "# device = 'cpu'\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining Result Dicts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def createDictElement(r):\n",
    "    total_loss, f1, acc, prec, rec, time = r\n",
    "    tmp = {}\n",
    "    tmp[\"total_loss\"] = total_loss\n",
    "    tmp[\"f1_score\"] = f1\n",
    "    tmp[\"accuracy\"] = acc\n",
    "    tmp[\"precision\"] = prec\n",
    "    tmp[\"recall\"] = rec\n",
    "    tmp[\"time\"] = time\n",
    "    return tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading of dataset and nan-removal\n",
    "Uncomment function-call to redo preprocessing\n",
    "Result is saved in data/data.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def pre_process():\n",
    "    data = pd.read_csv('WELFake_Dataset.csv', index_col=0)\n",
    "    # display(data[:300])\n",
    "    for i,x in data.iterrows():\n",
    "        if len(str(x[\"text\"])) <= 10:\n",
    "            data.loc[i, \"text\"] = np.nan\n",
    "        if len(str(x[\"title\"])) <= 10:\n",
    "            data.loc[i, \"title\"] = np.nan\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.to_csv(\"data/data.csv\")\n",
    "    display(data[:300])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data.csv\"):\n",
    "    pre_process()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization\n",
    "Uncomment function-call to redo tokenization for data/data.csv\n",
    "Result is saved in data/data_token.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def tokenize():\n",
    "    stop = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    punc = [u'\\u201c',u'\\u201d',u'\\u2018',u'\\u2019',u'\\u2024',u'\\u2025',u'\\u2026',u'\\u2027']\n",
    "    # print(punc)\n",
    "    data = pd.read_csv('data/data.csv', index_col=0)\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    for i, row in data.iterrows():\n",
    "        title = str(row[\"title\"])\n",
    "        text = str(row[\"text\"])\n",
    "        t1 = \"\"\n",
    "        for c in title:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t1 += c\n",
    "            else:\n",
    "                t1 += \" \"\n",
    "        t2 = \"\"\n",
    "        for c in text:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t2 += c\n",
    "            else:\n",
    "                t2 += \" \"\n",
    "        title_tokens = nltk.tokenize.word_tokenize(t1)\n",
    "        text_tokens = nltk.tokenize.word_tokenize(t2)\n",
    "        # title_filtered = [w.lower() for w in title_tokens if not w.lower() in string.punctuation]\n",
    "        # title_filtered = [w.lower() for w in title_filtered if not w.lower() in punc]\n",
    "        title_filtered = [w.lower() for w in title_tokens if not w.lower() in stop]\n",
    "        title_stemmed = [stemmer.stem(w) for w in title_filtered]\n",
    "        # text_filtered = [w.lower() for w in text_tokens if not w.lower() in string.punctuation]\n",
    "        # text_filtered = [w.lower() for w in text_filtered if not w.lower() in punc]\n",
    "        text_filtered = [w.lower() for w in text_tokens if not w.lower() in stop]\n",
    "        text_stemmed = [stemmer.stem(w) for w in text_filtered]\n",
    "        # print(title_stemmed)\n",
    "        # print(text_stemmed)\n",
    "        titles.append(title_stemmed)\n",
    "        texts.append(text_stemmed)\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_cleaned = pd.DataFrame(data=d)\n",
    "    # data_cleaned[\"title\"] = titles\n",
    "    # data_cleaned[\"text\"] = texts\n",
    "    data_cleaned.to_csv(\"data/data_token.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_token.csv\"):\n",
    "    tokenize()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of Words\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def make_bow(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    bow = []\n",
    "    bow_title = []\n",
    "    bow_text = []\n",
    "    bow_both = []\n",
    "    for i, row in data.iterrows():\n",
    "        words = row[\"title\"].split(\",\")\n",
    "        title = []\n",
    "        for word in words:\n",
    "            title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        words = row[\"text\"].split(\",\")\n",
    "        text = []\n",
    "        for word in words:\n",
    "            text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        dic_title = {}\n",
    "        dic_text = {}\n",
    "        dic_both = {}\n",
    "        for word in title:\n",
    "            if word in dic_title:\n",
    "                dic_title[word] = dic_title[word] + 1\n",
    "            else:\n",
    "                dic_title[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        for word in text:\n",
    "            if word in dic_text:\n",
    "                dic_text[word] = dic_text[word] + 1\n",
    "            else:\n",
    "                dic_text[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        bow_text.append(dic_text)\n",
    "        bow_title.append(dic_title)\n",
    "        bow_both.append(dic_both)\n",
    "    bow.append(bow_title)\n",
    "    bow.append(bow_text)\n",
    "    bow.append(bow_both)\n",
    "    return bow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# bow = [bow_title[],bow_text[],bow_both[]]\n",
    "# bow = make_bow('data_tokenized/data_token.csv') # was uncommented"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TFIDF with Cosine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def tf(bow_):\n",
    "    tf_ = []\n",
    "    for dic in bow_:\n",
    "        max_ = 0\n",
    "        for i in dic:\n",
    "            if dic[i] > max_:\n",
    "                max_ = dic[i]\n",
    "        tf_dic = {}\n",
    "        for word in dic:\n",
    "            tf_dic[word] = dic[word]/max_\n",
    "        tf_.append(tf_dic)\n",
    "    return tf_\n",
    "\n",
    "def idf(bow_):\n",
    "    df_ = {}\n",
    "    for dic in bow_:\n",
    "        for word in dic:\n",
    "            if word in df_:\n",
    "                df_[word] += 1\n",
    "            else:\n",
    "                df_[word] = 1\n",
    "    idf_ = {}\n",
    "    for word in df_:\n",
    "        idf_[word] = math.log10(len(bow)/df_[word])\n",
    "    return idf_\n",
    "\n",
    "def tf_idf(bow_):\n",
    "    tf_ = tf(bow_)\n",
    "    idf_ = idf(bow_)\n",
    "    tfidf = []\n",
    "    for dic in tf_:\n",
    "        tfidf_dic = {}\n",
    "        for word in dic:\n",
    "            tfidf_dic[word] = dic[word] * idf_[word]\n",
    "        tfidf.append(tfidf_dic)\n",
    "    return tfidf\n",
    "\n",
    "def cosineSim(dic_a, dic_b):\n",
    "    for word in dic_a:\n",
    "        if word not in dic_b:\n",
    "            dic_b[word] = 0\n",
    "    for word in dic_b:\n",
    "        if word not in dic_a:\n",
    "            dic_a[word] = 0\n",
    "    dot, sum_a, sum_b = 0,0,0\n",
    "    for word in dic_a:\n",
    "        a = dic_a[word]\n",
    "        b = dic_b[word]\n",
    "        dot += (a*b)\n",
    "        sum_a += math.pow(a,2)\n",
    "        sum_b += math.pow(b,2)\n",
    "    sqrt_sum_a = math.sqrt(sum_a)\n",
    "    sqrt_sum_b = math.sqrt(sum_b)\n",
    "    return dot / (sqrt_sum_a * sqrt_sum_b)\n",
    "\n",
    "def tfidf_cosine_ranking(word_, bow_):\n",
    "    tfidf_all = tf_idf(bow_)\n",
    "    list_query = [{word_: 1}]\n",
    "    tfidf_query = tf_idf(list_query)[0]\n",
    "    article_index = []\n",
    "    cosSim = []\n",
    "    cos_index = 0\n",
    "    for a in tfidf_all:\n",
    "        article_index.append(cos_index)\n",
    "        cosSim.append(cosineSim(a,tfidf_query))\n",
    "        cos_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': cosSim }).sort_values(by=['value'], ascending=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#cos_rank = tfidf_cosine_ranking('obama',bow[2])\n",
    "#print(cos_rank.head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bm25"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def bm25_ranking(query_,index_):\n",
    "    data = pd.read_csv('data_tokenized/data_token.csv', index_col=0)\n",
    "    corpus = []\n",
    "    title = []\n",
    "    text = []\n",
    "    both = []\n",
    "    for i, row in data.iterrows():\n",
    "            words = row[\"title\"].split(\",\")\n",
    "            for word in words:\n",
    "                title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "            words = row[\"text\"].split(\",\")\n",
    "            for word in words:\n",
    "                text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    if index_ == 0:\n",
    "        corpus = title\n",
    "    elif index_ == 1:\n",
    "        corpus = text\n",
    "    else:\n",
    "        for i in title:\n",
    "            both.append(title + text)\n",
    "        corpus = both\n",
    "\n",
    "    print(\"Starting bm25\")\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "    bm25_scores = bm25.get_scores(query_.split(\" \"))\n",
    "\n",
    "    article_index = []\n",
    "    bm25_index = 0\n",
    "    for a in bm25_scores:\n",
    "        article_index.append(bm25_index)\n",
    "        bm25_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': bm25_scores }).sort_values(by=['value'], ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# bm25_rank = bm25_ranking('sunday',bow[2]) # was uncommented\n",
    "# print(bm25_rank.head(5)) # was uncommented"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating and Training Word2Vec Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m load_model_from_disc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m      2\u001B[0m w2v_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata/data_token.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# for i, row in data.iterrows():\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#     print(type(row[\"title\"]))\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#     print(row)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#     data.loc[i, \"title\"] = ast.literal_eval(row[\"title\"])\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m#     data.loc[i, \"text\"] = ast.literal_eval(row[\"text\"])\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load_model_from_disc:\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 611\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1771\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1773\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1774\u001B[0m     (\n\u001B[0;32m   1775\u001B[0m         index,\n\u001B[0;32m   1776\u001B[0m         columns,\n\u001B[0;32m   1777\u001B[0m         col_dict,\n\u001B[1;32m-> 1778\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[0;32m   1779\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[0;32m   1780\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1782\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[1;32m--> 230\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m    232\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\Uni\\7.Semester\\AIR\\venv\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mParserError\u001B[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "load_model_from_disc = True\n",
    "w2v_model = None\n",
    "data = pd.read_csv('data/data_token.csv', index_col=0)\n",
    "# for i, row in data.iterrows():\n",
    "#     print(type(row[\"title\"]))\n",
    "#     print(row)\n",
    "#     data.loc[i, \"title\"] = ast.literal_eval(row[\"title\"])\n",
    "#     data.loc[i, \"text\"] = ast.literal_eval(row[\"text\"])\n",
    "if load_model_from_disc:\n",
    "    try:\n",
    "        w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if w2v_model is None or not load_model_from_disc:\n",
    "    if load_model_from_disc:\n",
    "        print(\"Could not load model from disc. Training model...\")\n",
    "    else:\n",
    "        print(\"Loading from disc deactivated. Training model...\")\n",
    "\n",
    "    class MySentences(object):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def __iter__(self):\n",
    "            for doc in pd.concat([data[\"text\"], data[\"title\"]]): #change to \"title\" or combine both\n",
    "                doc = ast.literal_eval(doc)\n",
    "                yield doc\n",
    "\n",
    "    sentences = MySentences(data)\n",
    "\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(min_count=20,\n",
    "                         window=2,\n",
    "                         sample=6e-5,\n",
    "                         alpha=0.03,\n",
    "                         min_alpha=0.0007,\n",
    "                         negative=20,\n",
    "                         workers=cores-1)\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    t = time.time()\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=3, report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time.time() - t) / 60, 2)))\n",
    "    w2v_model.save(\"word2vec.model\")\n",
    "else:\n",
    "    print(\"Model loaded from disc.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"amazon\", 'nazi')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"obama\", 'trump')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# find out which element doesn't match\n",
    "w2v_model.wv.doesnt_match(['amazon', 'obama', 'trump'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Which word is to obama as georg is to bush?\n",
    "w2v_model.wv.most_similar(positive=[\"obama\", \"georg\"], negative=[\"bush\"], topn=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"obama\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"presid\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Doc2Vec\n",
    "word2vec for each word with average over document"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creates w2v representation for all documents and titles\n",
    "def doc2vec():\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    start = time.time()\n",
    "    for i, row in data.iterrows():\n",
    "        vec_title = np.zeros(shape=w2v_model.vector_size)\n",
    "        vec_text = np.zeros(shape=w2v_model.vector_size)\n",
    "        tit = ast.literal_eval(row[\"title\"])\n",
    "        tex = ast.literal_eval(row[\"text\"])\n",
    "        tit_cnt = 0\n",
    "        tex_cnt = 0\n",
    "        for word in tit:\n",
    "            try:\n",
    "                vec_title += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tit_cnt += 1\n",
    "                pass\n",
    "        for word in tex:\n",
    "            try:\n",
    "                vec_text += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tex_cnt += 1\n",
    "                pass\n",
    "        if len(tit) > tit_cnt:\n",
    "            vec_title /= (len(tit) - tit_cnt)\n",
    "        if len(tex) > tex_cnt:\n",
    "            vec_text /= (len(tex) - tex_cnt)\n",
    "        titles.append(vec_title.tolist())\n",
    "        texts.append(vec_text.tolist())\n",
    "        if i % 5000 == 0:\n",
    "            print(\"[{}/{}] - {:.1f}s\".format(i, len(data.index), time.time() - start))\n",
    "    end = time.time()\n",
    "    print(\"creating doc2vec took {:.1f}s\".format(end - start))\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_w2v = pd.DataFrame(data=d)\n",
    "    data_w2v.to_pickle(\"data/data_w2v.pkl\")\n",
    "    display(data_w2v[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_w2v.pkl\"):\n",
    "    doc2vec()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test-split and Dataloader Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels = list()\n",
    "    texts = list()\n",
    "    for (_text, _label) in batch:\n",
    "        labels.append(_label)\n",
    "        texts.append(_text)\n",
    "\n",
    "    return torch.tensor(texts), torch.tensor(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "batch_size = 100\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'collate_fn': collate_batch,\n",
    "          'drop_last': True}\n",
    "\n",
    "\n",
    "data_d2v = pd.read_pickle(\"data/data_w2v.pkl\")\n",
    "titles = list()\n",
    "texts = list()\n",
    "# print(\"interpreting data\")\n",
    "# for i, row in data_d2v.iterrows():\n",
    "#     titles.append(ast.literal_eval(row[\"title\"]))\n",
    "#     texts.append(ast.literal_eval(row[\"text\"]))\n",
    "# print(\"done interpreting data\")\n",
    "# data_d2v[\"title\"] = titles\n",
    "# data_d2v[\"text\"] = texts\n",
    "\n",
    "data_d2v_title = data_d2v[[\"title\", \"label\"]].copy()\n",
    "data_d2v_text = data_d2v[[\"text\", \"label\"]].copy()\n",
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(data_d2v_title[\"title\"], data_d2v_title[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(data_d2v_text[\"text\"], data_d2v_text[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "\n",
    "X_train_title.reset_index(drop=True, inplace=True)\n",
    "X_test_title.reset_index(drop=True, inplace=True)\n",
    "y_train_title.reset_index(drop=True, inplace=True)\n",
    "y_test_title.reset_index(drop=True, inplace=True)\n",
    "X_train_text.reset_index(drop=True, inplace=True)\n",
    "X_test_text.reset_index(drop=True, inplace=True)\n",
    "y_train_text.reset_index(drop=True, inplace=True)\n",
    "y_test_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "class data_set(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(Dataset, self).__init__()\n",
    "        assert len(X.index) == len(y.index)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "train_dataset_title = data_set(X_train_title, y_train_title)\n",
    "test_dataset_title = data_set(X_test_title, y_test_title)\n",
    "train_dataset_text = data_set(X_train_text, y_train_text)\n",
    "test_dataset_text = data_set(X_test_text, y_test_text)\n",
    "\n",
    "train_dataloader_title = DataLoader(train_dataset_title, **params)\n",
    "test_dataloader_title = DataLoader(test_dataset_title, **params)\n",
    "train_dataloader_text = DataLoader(train_dataset_text, **params)\n",
    "test_dataloader_text = DataLoader(test_dataset_text, **params)\n",
    "\n",
    "for batch, (X, y) in enumerate(train_dataloader_title):\n",
    "    # print(X)\n",
    "    # print(X.shape)\n",
    "    # print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_metrics_to_log(log, metrics, y_true, y_pred, prefix=''):\n",
    "    for metric in metrics:\n",
    "        q = metric(y_true, y_pred)\n",
    "        log[prefix + metric.__name__] = q\n",
    "    return\n",
    "\n",
    "def log_to_message(log, precision=4):\n",
    "    fmt = \"{0}: {1:.\" + str(precision) + \"f}\"\n",
    "    return \"    \".join(fmt.format(k, v) for k, v in log.items())\n",
    "\n",
    "class ProgressBar(object):\n",
    "    \"\"\"Cheers @ajratner\"\"\"\n",
    "\n",
    "    def __init__(self, n, length=40):\n",
    "        # Protect against division by zero\n",
    "        self.n      = max(1, n)\n",
    "        self.nf     = float(n)\n",
    "        self.length = length\n",
    "        # Precalculate the i values that should trigger a write operation\n",
    "        self.ticks = set([round(i/100.0 * n) for i in range(101)])\n",
    "        self.ticks.add(n-1)\n",
    "        self.bar(0)\n",
    "\n",
    "    def bar(self, i, message=\"\"):\n",
    "        \"\"\"Assumes i ranges through [0, n-1]\"\"\"\n",
    "        if i in self.ticks:\n",
    "            b = int(np.ceil(((i+1) / self.nf) * self.length))\n",
    "            sys.stdout.write(\"\\r[{0}{1}] {2}%\\t{3}\".format(\n",
    "                \"=\"*b, \" \"*(self.length-b), int(100*((i+1) / self.nf)), message\n",
    "            ))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    def close(self, message=\"\"):\n",
    "        # Move the bar to 100% before closing\n",
    "        self.bar(self.n-1)\n",
    "        sys.stdout.write(\"\\n{0}\\n\\n\".format(message))\n",
    "        sys.stdout.flush()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    start_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    f1 = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    accuracy = 0\n",
    "    f1_score_ = BinaryF1Score().to(device)\n",
    "    precision_ = BinaryPrecision().to(device)\n",
    "    recall_ = BinaryRecall().to(device)\n",
    "    accuracy_ = BinaryAccuracy().to(device)\n",
    "    pb = ProgressBar(size/batch_size)\n",
    "    log = OrderedDict()\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.squeeze(), y.float())\n",
    "        total_loss += loss.item()\n",
    "        f1 += f1_score_(pred.squeeze(), y)\n",
    "        precision += precision_(pred.squeeze(), y)\n",
    "        recall += recall_(pred.squeeze(), y)\n",
    "        accuracy += accuracy_(pred.squeeze(), y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        log['loss'] = float(loss) / (batch + 1)\n",
    "        log['f1'] = float(f1) / (batch + 1)\n",
    "        log['accuracy'] = float(accuracy) / (batch + 1) #correct / ((batch + 1) * batch_size)\n",
    "        log['precision'] = float(precision) / (batch + 1)\n",
    "        log['recall'] = float(recall) / (batch + 1)\n",
    "        log['time'] = time.time() - start_time\n",
    "        pb.bar(batch, log_to_message(log))\n",
    "    pb.close(log_to_message(log))\n",
    "    return total_loss, (f1/num_batches).item(), (accuracy/num_batches).item(), (precision/num_batches).item(), (recall/num_batches).item(), time.time()-start_time\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    start_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    f1 = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    accuracy = 0\n",
    "    f1_score_ = BinaryF1Score().to(device)\n",
    "    precision_ = BinaryPrecision().to(device)\n",
    "    recall_ = BinaryRecall().to(device)\n",
    "    accuracy_ = BinaryAccuracy().to(device)\n",
    "    pb = ProgressBar(size/batch_size)\n",
    "    log = OrderedDict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred.squeeze(), y.float())\n",
    "            f1 += f1_score_(pred.squeeze(), y)\n",
    "            precision += precision_(pred.squeeze(), y)\n",
    "            recall += recall_(pred.squeeze(), y)\n",
    "            accuracy += accuracy_(pred.squeeze(), y)\n",
    "            # Backpropagation\n",
    "            log['loss'] = float(test_loss) / (batch + 1)\n",
    "            log['f1'] = float(f1) / (batch + 1)\n",
    "            log['accuracy'] = float(accuracy) / (batch + 1) #correct / ((batch + 1) * batch_size)\n",
    "            log['precision'] = float(precision) / (batch + 1)\n",
    "            log['recall'] = float(recall) / (batch + 1)\n",
    "            log['time'] = time.time() - start_time\n",
    "            pb.bar(batch, log_to_message(log))\n",
    "    pb.close(log_to_message(log))\n",
    "    return test_loss.item(), (f1/num_batches).item(), (accuracy/num_batches).item(), (precision/num_batches).item(), (recall/num_batches).item(), time.time()-start_time\n",
    "\n",
    "def train_and_evaluate(train_dataloader, test_dataloader, model, loss_fn, optimizer, training=True):\n",
    "    if training:\n",
    "        for i in range(epochs):\n",
    "            print(\"Epoch {}: ------------------------------------------------------------------------------------------------------------------------\".format(i+1))\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "    print(\"Evaluation ------------------------------------------------------------------------------------------------------------------------\")\n",
    "    return test(test_dataloader, model, loss_fn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Model for testing of training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, vec):\n",
    "        x = self.relu(self.fc1(vec))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return torch.sigmoid(self.fc4(x))\n",
    "\n",
    "model = SimpleLinearModel().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_title, test_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"simple_linear_model\"] = {}\n",
    "results[\"simple_linear_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "model = SimpleLinearModel().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_text, test_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"simple_linear_model\"][\"text\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Convolution Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SimpleConvolutionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvolutionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, 100)\n",
    "        self.conv = nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.conv(x.unsqueeze(1))\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.squeeze()\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleConvolutionModel().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "results[\"simple_convolution_model\"] = {}\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_title, test_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"simple_convolution_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "model = SimpleConvolutionModel().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_text, test_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"simple_convolution_model\"][\"text\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FA_KES(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FA_KES, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, 100)\n",
    "        # self.embed = nn.Embedding(\n",
    "        #     num_embeddings=len(w2v_model.wv),\n",
    "        #     embedding_dim=100)\n",
    "        self.conv = nn.Conv1d(in_channels=100, out_channels=100, kernel_size=6, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "        # self.fc2 = nn.Linear(95, 1)\n",
    "        self.lstm = nn.LSTM(96, 32, 3, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(self.conv(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.squeeze()\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = FA_KES().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "results[\"lstm_model\"] = {}\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_title, test_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"lstm_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "model = FA_KES().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_text, test_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"lstm_model\"][\"text\"] = createDictElement(r)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Using a support vector machine (SVM) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def svm(X_train_data, y_train_data, X_test_data, y_test_data):\n",
    "    X_train = X_train_data.tolist()\n",
    "    X_test = X_test_data.tolist()\n",
    "    start_time = time.time()\n",
    "    clf = SVC(kernel='rbf')\n",
    "    print(\"fitting...\")\n",
    "    clf.fit(X_train,y_train_data)\n",
    "    print(\"predicting...\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return 0, f1_score(y_test_data,y_pred), accuracy_score(y_test_data, y_pred), precision_score(y_test_data, y_pred), recall_score(y_test_data, y_pred), time.time()-start_time\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r = svm(X_train_text, y_train_text, X_test_text, y_test_text)\n",
    "loss, f1_score_text, accuracy_text, precision_text, recall_text, time_text = r\n",
    "print(\"Accuracy for text: {:.2f}%\\nF1 score for text: {:.2f}%\\nPrecision score for text: {:.2f}%\\nRecall score for text: {:.2f}%\".format(accuracy_text*100, f1_score_text*100, precision_text*100, recall_text*100))\n",
    "results[\"support_vector_machine\"] = {}\n",
    "results[\"support_vector_machine\"][\"text\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r = svm(X_train_title, y_train_title, X_test_title, y_test_title)\n",
    "loss, f1_score_title, accuracy_title, precision_title, recall_title, time_title = r\n",
    "print(\"Accuracy for title: {:.2f}%\\nF1 score for title: {:.2f}%\\nPrecision score for title: {:.2f}%\\nRecall score for title: {:.2f}%\".format(accuracy_title*100, f1_score_title*100, precision_title*100, recall_title*100))\n",
    "results[\"support_vector_machine\"][\"title\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Algorithm\n",
    "\n",
    "Using the random forest algorithm (RF) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test, name, crit='gini'):\n",
    "    start_time = time.time()\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, random_state = 42, verbose=0, n_jobs=-1, criterion=crit)\n",
    "    rf.fit(X_train.tolist(), y_train.tolist())\n",
    "    y_pred = rf.predict(X_test.tolist())\n",
    "    acc = accuracy_score(y_test.tolist(), y_pred)\n",
    "    f1 = f1_score(y_test.tolist(), y_pred)\n",
    "    prec = precision_score(y_test.tolist(), y_pred)\n",
    "    rec = recall_score(y_test.tolist(), y_pred)\n",
    "    print(\"accuracy for random forest with {} criterion {}: {:.2f}%\".format(crit, name, acc*100))\n",
    "    print(\"f1 score for random forest with {} criterion{}: {:.2f}%\".format(crit, name, f1*100))\n",
    "    print(\"precision score random forest with {} criterion for {}: {:.2f}%\".format(crit, name, prec*100))\n",
    "    print(\"recall score for random forest with {} criterion {}: {:.2f}%\".format(crit, name, rec*100))\n",
    "    return 0, f1, acc, prec, rec, time.time()-start_time\n",
    "\n",
    "results[\"random_forest\"] = {}\n",
    "r = random_forest(X_train_text, X_test_text, y_train_text, y_test_text, \"w2v text\")\n",
    "results[\"random_forest\"][\"text\"] = createDictElement(r)\n",
    "r = random_forest(X_train_title, X_test_title, y_train_title, y_test_title, \"w2v title\")\n",
    "results[\"random_forest\"][\"title\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prinicipal Component Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not connect to 127.0.0.1: 50702\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\JetBrains\\PyCharm 2022.2.2\\plugins\\python\\helpers\\pydev\\_pydevd_bundle\\pydevd_comm.py\", line 463, in start_client\n",
      "    s.connect((host, port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\JetBrains\\PyCharm 2022.2.2\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_utils.py\", line 81, in attach_to_debugger\n",
      "    debugger.connect(pydev_localhost.get_localhost(), debugger_port)\n",
      "  File \"C:\\Program Files\\JetBrains\\PyCharm 2022.2.2\\plugins\\python\\helpers\\pydev\\pydevd.py\", line 660, in connect\n",
      "    s = start_client(host, port)\n",
      "  File \"C:\\Program Files\\JetBrains\\PyCharm 2022.2.2\\plugins\\python\\helpers\\pydev\\_pydevd_bundle\\pydevd_comm.py\", line 463, in start_client\n",
      "    s.connect((host, port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "Failed to connect to target debugger.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pca_(X_test, y_test):\n",
    "    pca = PCA()\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('pca', pca)])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    Xt = pipe.fit_transform(X_test.tolist())\n",
    "    plot = plt.scatter(Xt[:,0], Xt[:,1], c=y_test.tolist(), alpha=0.6, s=0.9, cmap='plasma')\n",
    "    plt.legend(handles=plot.legend_elements()[0], labels=[\"real news\", \"fake news\"])\n",
    "    plt.show()\n",
    "\n",
    "pca_(X_test_text, y_test_text)\n",
    "pca_(X_test_title, y_test_title)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def wc(label):\n",
    "    data_pre = pd.read_csv(\"data_tokenized/data_token_no_stem.csv\", index_col=0)\n",
    "    data_pre_real = data_pre.loc[data_pre[\"label\"] == label]\n",
    "    data_pre = None\n",
    "    x = \"\"\n",
    "    for i, vals in data_pre_real.iterrows():\n",
    "        for val in ast.literal_eval(vals[\"title\"]):\n",
    "            x += \" \"\n",
    "            x += val\n",
    "        # if i % 1000 == 0:\n",
    "        #     print(i)\n",
    "\n",
    "    wordcloud = WordCloud(max_font_size=100, max_words=75, background_color=\"white\", width=600, height=400, colormap='tab20b').generate(x)\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    if not os.path.exists(\"figures\"):\n",
    "        os.mkdir(\"figures\")\n",
    "    plt.savefig(\"figures/word_cloud_{}.png\".format(\"real\" if label == 1 else \"fake\"))\n",
    "wc(0)\n",
    "wc(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting Results\n",
    "### Compare Scores between algorithms (F1-Score and Accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 8})\n",
    "fig, ax = plt.subplots(2, figsize=(8,8))\n",
    "plt.suptitle(\"F1-score and accuracy of the different algorithms\")\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "def setSubplots1(input, axis_x):\n",
    "    ax[axis_x].set_ylim(0.8, 1.0)\n",
    "    algorithms = []\n",
    "    f1s = []\n",
    "    accs = []\n",
    "    for element in results:\n",
    "        algorithms.append(element)\n",
    "        f1s.append(round(results[element][input][\"f1_score\"],4))\n",
    "        accs.append(round(results[element][input][\"accuracy\"],4))\n",
    "\n",
    "    x = np.arange(len(algorithms))  # the label locations\n",
    "\n",
    "    rects1 = ax[axis_x].bar(x - width/2, f1s, width, label='F1-Score')\n",
    "    rects2 = ax[axis_x].bar(x + width/2, accs, width, label='Accuracy')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax[axis_x].set_ylabel('Scores')\n",
    "    ax[axis_x].set_title(input + ' input')\n",
    "    ax[axis_x].set_xticks(x, algorithms)\n",
    "    ax[axis_x].legend()\n",
    "\n",
    "    ax[axis_x].bar_label(rects1, padding=3)\n",
    "    ax[axis_x].bar_label(rects2, padding=3)\n",
    "\n",
    "setSubplots1(\"text\", 0)\n",
    "setSubplots1(\"title\", 1)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare scores between different inputs (text and title)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = [\"f1_score\", \"accuracy\", \"precision\", \"recall\"]\n",
    "x = np.arange(len(scores))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "fig, ax = plt.subplots(3, 2, figsize=(16,8))\n",
    "plt.suptitle(\"Scores for tet and title input\")\n",
    "\n",
    "def setSubplot(algorithm, axis_x, axis_y):\n",
    "    title_values = []\n",
    "    text_values = []\n",
    "    for element in results[algorithm][\"text\"]:\n",
    "        text_values.append(round(results[algorithm][\"text\"][element],4))\n",
    "    for element in results[algorithm][\"title\"]:\n",
    "        title_values.append(round(results[algorithm][\"title\"][element],4))\n",
    "    title_values.pop()\n",
    "    text_values.pop()\n",
    "    title_values.pop(0)\n",
    "    text_values.pop(0)\n",
    "\n",
    "    rects1 = ax[axis_x][axis_y].bar(x - width/2, text_values, width, label='Text')\n",
    "    rects2 = ax[axis_x][axis_y].bar(x + width/2, title_values, width, label='Title')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax[axis_x][axis_y].set_ylabel('Scores')\n",
    "    ax[axis_x][axis_y].set_title(algorithm)\n",
    "    ax[axis_x][axis_y].set_xticks(x, scores)\n",
    "    ax[axis_x][axis_y].legend()\n",
    "\n",
    "    ax[axis_x][axis_y].bar_label(rects1, padding=3)\n",
    "    ax[axis_x][axis_y].bar_label(rects2, padding=3)\n",
    "    ax[axis_x][axis_y].set_ylim(0.7, 1.0)\n",
    "\n",
    "setSubplot(\"simple_linear_model\", 0, 0)\n",
    "setSubplot(\"simple_convolution_model\", 0, 1)\n",
    "setSubplot(\"support_vector_machine\", 1, 0)\n",
    "setSubplot(\"random_forest\", 1, 1)\n",
    "setSubplot(\"lstm_model\", 2, 0)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
