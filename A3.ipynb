{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AIR Project\n",
    "## Group 17\n",
    "\n",
    "We are using a dataset which includes non-fake as well as fake news (labeled dataset).\n",
    "https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and specific settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import ast\n",
    "import os.path\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryRecall, BinaryPrecision, BinaryAccuracy\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running models with cpu\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"running models with {}\".format(device))\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining Result Dicts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def createDictElement(r):\n",
    "    total_loss, f1, acc, prec, rec, time = r\n",
    "    tmp = {}\n",
    "    tmp[\"total_loss\"] = total_loss\n",
    "    tmp[\"f1_score\"] = f1\n",
    "    tmp[\"accuracy\"] = acc\n",
    "    tmp[\"precision\"] = prec\n",
    "    tmp[\"recall\"] = rec\n",
    "    tmp[\"time\"] = time\n",
    "    return tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading of dataset and nan-removal\n",
    "Uncomment function-call to redo preprocessing\n",
    "Result is saved in data/data.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def pre_process():\n",
    "    data = pd.read_csv('WELFake_Dataset.csv', index_col=0)\n",
    "    # display(data[:300])\n",
    "    for i,x in data.iterrows():\n",
    "        if len(str(x[\"text\"])) <= 10:\n",
    "            data.loc[i, \"text\"] = np.nan\n",
    "        if len(str(x[\"title\"])) <= 10:\n",
    "            data.loc[i, \"title\"] = np.nan\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.to_csv(\"data/data.csv\")\n",
    "    display(data[:300])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data.csv\"):\n",
    "    pre_process()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization\n",
    "Uncomment function-call to redo tokenization for data/data.csv\n",
    "Result is saved in data/data_token.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def tokenize():\n",
    "    stop = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    punc = [u'\\u201c',u'\\u201d',u'\\u2018',u'\\u2019',u'\\u2024',u'\\u2025',u'\\u2026',u'\\u2027']\n",
    "    # print(punc)\n",
    "    data = pd.read_csv('data/data.csv', index_col=0)\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    for i, row in data.iterrows():\n",
    "        title = str(row[\"title\"])\n",
    "        text = str(row[\"text\"])\n",
    "        t1 = \"\"\n",
    "        for c in title:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t1 += c\n",
    "            else:\n",
    "                t1 += \" \"\n",
    "        t2 = \"\"\n",
    "        for c in text:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t2 += c\n",
    "            else:\n",
    "                t2 += \" \"\n",
    "        title_tokens = nltk.tokenize.word_tokenize(t1)\n",
    "        text_tokens = nltk.tokenize.word_tokenize(t2)\n",
    "        # title_filtered = [w.lower() for w in title_tokens if not w.lower() in string.punctuation]\n",
    "        # title_filtered = [w.lower() for w in title_filtered if not w.lower() in punc]\n",
    "        title_filtered = [w.lower() for w in title_tokens if not w.lower() in stop]\n",
    "        title_stemmed = [stemmer.stem(w) for w in title_filtered]\n",
    "        # text_filtered = [w.lower() for w in text_tokens if not w.lower() in string.punctuation]\n",
    "        # text_filtered = [w.lower() for w in text_filtered if not w.lower() in punc]\n",
    "        text_filtered = [w.lower() for w in text_tokens if not w.lower() in stop]\n",
    "        text_stemmed = [stemmer.stem(w) for w in text_filtered]\n",
    "        # print(title_stemmed)\n",
    "        # print(text_stemmed)\n",
    "        titles.append(title_stemmed)\n",
    "        texts.append(text_stemmed)\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_cleaned = pd.DataFrame(data=d)\n",
    "    # data_cleaned[\"title\"] = titles\n",
    "    # data_cleaned[\"text\"] = texts\n",
    "    data_cleaned.to_csv(\"data/data_token.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_token.csv\"):\n",
    "    tokenize()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of Words\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def make_bow(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    bow = []\n",
    "    bow_title = []\n",
    "    bow_text = []\n",
    "    bow_both = []\n",
    "    for i, row in data.iterrows():\n",
    "        words = row[\"title\"].split(\",\")\n",
    "        title = []\n",
    "        for word in words:\n",
    "            title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        words = row[\"text\"].split(\",\")\n",
    "        text = []\n",
    "        for word in words:\n",
    "            text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        dic_title = {}\n",
    "        dic_text = {}\n",
    "        dic_both = {}\n",
    "        for word in title:\n",
    "            if word in dic_title:\n",
    "                dic_title[word] = dic_title[word] + 1\n",
    "            else:\n",
    "                dic_title[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        for word in text:\n",
    "            if word in dic_text:\n",
    "                dic_text[word] = dic_text[word] + 1\n",
    "            else:\n",
    "                dic_text[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        bow_text.append(dic_text)\n",
    "        bow_title.append(dic_title)\n",
    "        bow_both.append(dic_both)\n",
    "    bow.append(bow_title)\n",
    "    bow.append(bow_text)\n",
    "    bow.append(bow_both)\n",
    "    return bow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# bow = [bow_title[],bow_text[],bow_both[]]\n",
    "# bow = make_bow('data_tokenized/data_token.csv') # was uncommented"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TFIDF with Cosine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def tf(bow_):\n",
    "    tf_ = []\n",
    "    for dic in bow_:\n",
    "        max_ = 0\n",
    "        for i in dic:\n",
    "            if dic[i] > max_:\n",
    "                max_ = dic[i]\n",
    "        tf_dic = {}\n",
    "        for word in dic:\n",
    "            tf_dic[word] = dic[word]/max_\n",
    "        tf_.append(tf_dic)\n",
    "    return tf_\n",
    "\n",
    "def idf(bow_):\n",
    "    df_ = {}\n",
    "    for dic in bow_:\n",
    "        for word in dic:\n",
    "            if word in df_:\n",
    "                df_[word] += 1\n",
    "            else:\n",
    "                df_[word] = 1\n",
    "    idf_ = {}\n",
    "    for word in df_:\n",
    "        idf_[word] = math.log10(len(bow)/df_[word])\n",
    "    return idf_\n",
    "\n",
    "def tf_idf(bow_):\n",
    "    tf_ = tf(bow_)\n",
    "    idf_ = idf(bow_)\n",
    "    tfidf = []\n",
    "    for dic in tf_:\n",
    "        tfidf_dic = {}\n",
    "        for word in dic:\n",
    "            tfidf_dic[word] = dic[word] * idf_[word]\n",
    "        tfidf.append(tfidf_dic)\n",
    "    return tfidf\n",
    "\n",
    "def cosineSim(dic_a, dic_b):\n",
    "    for word in dic_a:\n",
    "        if word not in dic_b:\n",
    "            dic_b[word] = 0\n",
    "    for word in dic_b:\n",
    "        if word not in dic_a:\n",
    "            dic_a[word] = 0\n",
    "    dot, sum_a, sum_b = 0,0,0\n",
    "    for word in dic_a:\n",
    "        a = dic_a[word]\n",
    "        b = dic_b[word]\n",
    "        dot += (a*b)\n",
    "        sum_a += math.pow(a,2)\n",
    "        sum_b += math.pow(b,2)\n",
    "    sqrt_sum_a = math.sqrt(sum_a)\n",
    "    sqrt_sum_b = math.sqrt(sum_b)\n",
    "    return dot / (sqrt_sum_a * sqrt_sum_b)\n",
    "\n",
    "def tfidf_cosine_ranking(word_, bow_):\n",
    "    tfidf_all = tf_idf(bow_)\n",
    "    list_query = [{word_: 1}]\n",
    "    tfidf_query = tf_idf(list_query)[0]\n",
    "    article_index = []\n",
    "    cosSim = []\n",
    "    cos_index = 0\n",
    "    for a in tfidf_all:\n",
    "        article_index.append(cos_index)\n",
    "        cosSim.append(cosineSim(a,tfidf_query))\n",
    "        cos_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': cosSim }).sort_values(by=['value'], ascending=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "#cos_rank = tfidf_cosine_ranking('obama',bow[2])\n",
    "#print(cos_rank.head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bm25"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def bm25_ranking(query_,index_):\n",
    "    data = pd.read_csv('data_tokenized/data_token.csv', index_col=0)\n",
    "    corpus = []\n",
    "    title = []\n",
    "    text = []\n",
    "    both = []\n",
    "    for i, row in data.iterrows():\n",
    "            words = row[\"title\"].split(\",\")\n",
    "            for word in words:\n",
    "                title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "            words = row[\"text\"].split(\",\")\n",
    "            for word in words:\n",
    "                text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    if index_ == 0:\n",
    "        corpus = title\n",
    "    elif index_ == 1:\n",
    "        corpus = text\n",
    "    else:\n",
    "        for i in title:\n",
    "            both.append(title + text)\n",
    "        corpus = both\n",
    "\n",
    "    print(\"Starting bm25\")\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "    bm25_scores = bm25.get_scores(query_.split(\" \"))\n",
    "\n",
    "    article_index = []\n",
    "    bm25_index = 0\n",
    "    for a in bm25_scores:\n",
    "        article_index.append(bm25_index)\n",
    "        bm25_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': bm25_scores }).sort_values(by=['value'], ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# bm25_rank = bm25_ranking('sunday',bow[2]) # was uncommented\n",
    "# print(bm25_rank.head(5)) # was uncommented"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating and Training Word2Vec Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disc.\n"
     ]
    }
   ],
   "source": [
    "load_model_from_disc = True\n",
    "w2v_model = None\n",
    "data = pd.read_csv('data/data_token.csv', index_col=0)\n",
    "# for i, row in data.iterrows():\n",
    "#     print(type(row[\"title\"]))\n",
    "#     print(row)\n",
    "#     data.loc[i, \"title\"] = ast.literal_eval(row[\"title\"])\n",
    "#     data.loc[i, \"text\"] = ast.literal_eval(row[\"text\"])\n",
    "if load_model_from_disc:\n",
    "    try:\n",
    "        w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if w2v_model is None or not load_model_from_disc:\n",
    "    if load_model_from_disc:\n",
    "        print(\"Could not load model from disc. Training model...\")\n",
    "    else:\n",
    "        print(\"Loading from disc deactivated. Training model...\")\n",
    "\n",
    "    class MySentences(object):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def __iter__(self):\n",
    "            for doc in pd.concat([data[\"text\"], data[\"title\"]]): #change to \"title\" or combine both\n",
    "                doc = ast.literal_eval(doc)\n",
    "                yield doc\n",
    "\n",
    "    sentences = MySentences(data)\n",
    "\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(min_count=20,\n",
    "                         window=2,\n",
    "                         sample=6e-5,\n",
    "                         alpha=0.03,\n",
    "                         min_alpha=0.0007,\n",
    "                         negative=20,\n",
    "                         workers=cores-1)\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    t = time.time()\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=3, report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time.time() - t) / 60, 2)))\n",
    "    w2v_model.save(\"word2vec.model\")\n",
    "else:\n",
    "    print(\"Model loaded from disc.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.12460326"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"amazon\", 'nazi')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5865986"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"obama\", 'trump')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "'amazon'"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out which element doesn't match\n",
    "w2v_model.wv.doesnt_match(['amazon', 'obama', 'trump'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.6315594911575317),\n ('presid', 0.49833399057388306),\n ('outgo', 0.46703284978866577)]"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which word is to obama as georg is to bush?\n",
    "w2v_model.wv.most_similar(positive=[\"obama\", \"georg\"], negative=[\"bush\"], topn=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.83445143699646),\n ('presid', 0.6639242172241211),\n ('predecessor', 0.6574732661247253),\n ('administr', 0.6533365845680237),\n ('outgo', 0.6066954135894775),\n ('trump', 0.5865985155105591),\n ('bachelet', 0.5682237148284912),\n ('bush', 0.5610581040382385),\n ('undo', 0.5586986541748047),\n ('obama\\x92', 0.5423570275306702)]"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"obama\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.6808820962905884),\n ('obama', 0.6639242172241211),\n ('45th', 0.6278534531593323),\n ('successor', 0.6069088578224182),\n ('administr', 0.6057536005973816),\n ('predecessor', 0.6040663719177246),\n ('donald', 0.5951759815216064),\n ('outgo', 0.5931932330131531),\n ('trump', 0.5852926969528198),\n ('presidenti', 0.5783258676528931)]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"presid\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Doc2Vec\n",
    "word2vec for each word with average over document"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# creates w2v representation for all documents and titles\n",
    "def doc2vec():\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    start = time.time()\n",
    "    for i, row in data.iterrows():\n",
    "        vec_title = np.zeros(shape=w2v_model.vector_size)\n",
    "        vec_text = np.zeros(shape=w2v_model.vector_size)\n",
    "        tit = ast.literal_eval(row[\"title\"])\n",
    "        tex = ast.literal_eval(row[\"text\"])\n",
    "        tit_cnt = 0\n",
    "        tex_cnt = 0\n",
    "        for word in tit:\n",
    "            try:\n",
    "                vec_title += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tit_cnt += 1\n",
    "                pass\n",
    "        for word in tex:\n",
    "            try:\n",
    "                vec_text += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tex_cnt += 1\n",
    "                pass\n",
    "        if len(tit) > tit_cnt:\n",
    "            vec_title /= (len(tit) - tit_cnt)\n",
    "        if len(tex) > tex_cnt:\n",
    "            vec_text /= (len(tex) - tex_cnt)\n",
    "        titles.append(vec_title.tolist())\n",
    "        texts.append(vec_text.tolist())\n",
    "        if i % 5000 == 0:\n",
    "            print(\"[{}/{}] - {:.1f}s\".format(i, len(data.index), time.time() - start))\n",
    "    end = time.time()\n",
    "    print(\"creating doc2vec took {:.1f}s\".format(end - start))\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_w2v = pd.DataFrame(data=d)\n",
    "    data_w2v.to_pickle(\"data/data_w2v.pkl\")\n",
    "    display(data_w2v[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_w2v.pkl\"):\n",
    "    doc2vec()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test-split and Dataloader Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels = list()\n",
    "    texts = list()\n",
    "    for (_text, _label) in batch:\n",
    "        labels.append(_label)\n",
    "        texts.append(_text)\n",
    "\n",
    "    return torch.tensor(texts), torch.tensor(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'collate_fn': collate_batch,\n",
    "          'drop_last': True}\n",
    "\n",
    "\n",
    "data_d2v = pd.read_pickle(\"data/data_w2v.pkl\")\n",
    "titles = list()\n",
    "texts = list()\n",
    "# print(\"interpreting data\")\n",
    "# for i, row in data_d2v.iterrows():\n",
    "#     titles.append(ast.literal_eval(row[\"title\"]))\n",
    "#     texts.append(ast.literal_eval(row[\"text\"]))\n",
    "# print(\"done interpreting data\")\n",
    "# data_d2v[\"title\"] = titles\n",
    "# data_d2v[\"text\"] = texts\n",
    "\n",
    "data_d2v_title = data_d2v[[\"title\", \"label\"]].copy()\n",
    "data_d2v_text = data_d2v[[\"text\", \"label\"]].copy()\n",
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(data_d2v_title[\"title\"], data_d2v_title[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(data_d2v_text[\"text\"], data_d2v_text[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "\n",
    "X_train_title.reset_index(drop=True, inplace=True)\n",
    "X_test_title.reset_index(drop=True, inplace=True)\n",
    "y_train_title.reset_index(drop=True, inplace=True)\n",
    "y_test_title.reset_index(drop=True, inplace=True)\n",
    "X_train_text.reset_index(drop=True, inplace=True)\n",
    "X_test_text.reset_index(drop=True, inplace=True)\n",
    "y_train_text.reset_index(drop=True, inplace=True)\n",
    "y_test_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "class data_set(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(Dataset, self).__init__()\n",
    "        assert len(X.index) == len(y.index)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "train_dataset_title = data_set(X_train_title, y_train_title)\n",
    "test_dataset_title = data_set(X_test_title, y_test_title)\n",
    "train_dataset_text = data_set(X_train_text, y_train_text)\n",
    "test_dataset_text = data_set(X_test_text, y_test_text)\n",
    "\n",
    "train_dataloader_title = DataLoader(train_dataset_title, **params)\n",
    "test_dataloader_title = DataLoader(test_dataset_title, **params)\n",
    "train_dataloader_text = DataLoader(train_dataset_text, **params)\n",
    "test_dataloader_text = DataLoader(test_dataset_text, **params)\n",
    "\n",
    "for batch, (X, y) in enumerate(train_dataloader_title):\n",
    "    # print(X)\n",
    "    # print(X.shape)\n",
    "    # print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def add_metrics_to_log(log, metrics, y_true, y_pred, prefix=''):\n",
    "    for metric in metrics:\n",
    "        q = metric(y_true, y_pred)\n",
    "        log[prefix + metric.__name__] = q\n",
    "    return\n",
    "\n",
    "def log_to_message(log, precision=4):\n",
    "    fmt = \"{0}: {1:.\" + str(precision) + \"f}\"\n",
    "    return \"    \".join(fmt.format(k, v) for k, v in log.items())\n",
    "\n",
    "class ProgressBar(object):\n",
    "    \"\"\"Cheers @ajratner\"\"\"\n",
    "\n",
    "    def __init__(self, n, length=40):\n",
    "        # Protect against division by zero\n",
    "        self.n      = max(1, n)\n",
    "        self.nf     = float(n)\n",
    "        self.length = length\n",
    "        # Precalculate the i values that should trigger a write operation\n",
    "        self.ticks = set([round(i/100.0 * n) for i in range(101)])\n",
    "        self.ticks.add(n-1)\n",
    "        self.bar(0)\n",
    "\n",
    "    def bar(self, i, message=\"\"):\n",
    "        \"\"\"Assumes i ranges through [0, n-1]\"\"\"\n",
    "        if i in self.ticks:\n",
    "            b = int(np.ceil(((i+1) / self.nf) * self.length))\n",
    "            sys.stdout.write(\"\\r[{0}{1}] {2}%\\t{3}\".format(\n",
    "                \"=\"*b, \" \"*(self.length-b), int(100*((i+1) / self.nf)), message\n",
    "            ))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    def close(self, message=\"\"):\n",
    "        # Move the bar to 100% before closing\n",
    "        self.bar(self.n-1)\n",
    "        sys.stdout.write(\"\\n{0}\\n\\n\".format(message))\n",
    "        sys.stdout.flush()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    start_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    f1 = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    accuracy = 0\n",
    "    f1_score_ = BinaryF1Score().to(device)\n",
    "    precision_ = BinaryPrecision().to(device)\n",
    "    recall_ = BinaryRecall().to(device)\n",
    "    accuracy_ = BinaryAccuracy().to(device)\n",
    "    pb = ProgressBar(size/batch_size)\n",
    "    log = OrderedDict()\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.squeeze(), y.float())\n",
    "        total_loss += loss.item()\n",
    "        f1 += f1_score_(pred.squeeze(), y)\n",
    "        precision += precision_(pred.squeeze(), y)\n",
    "        recall += recall_(pred.squeeze(), y)\n",
    "        accuracy += accuracy_(pred.squeeze(), y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        log['loss'] = float(loss) / (batch + 1)\n",
    "        log['f1'] = float(f1) / (batch + 1)\n",
    "        log['accuracy'] = float(accuracy) / (batch + 1) #correct / ((batch + 1) * batch_size)\n",
    "        log['precision'] = float(precision) / (batch + 1)\n",
    "        log['recall'] = float(recall) / (batch + 1)\n",
    "        log['time'] = time.time() - start_time\n",
    "        pb.bar(batch, log_to_message(log))\n",
    "    pb.close(log_to_message(log))\n",
    "    return total_loss, (f1/num_batches).item(), (accuracy/num_batches).item(), (precision/num_batches).item(), (recall/num_batches).item(), time.time()-start_time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Model for testing of training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\toss: 0.0005    f1: 0.8510    accuracy: 0.8465    precision: 0.8425    recall: 0.8667    time: 5.1517\n",
      "loss: 0.0005    f1: 0.8509    accuracy: 0.8465    precision: 0.8424    recall: 0.8667    time: 5.1983\n",
      "\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8821    accuracy: 0.8812    precision: 0.8764    recall: 0.8921    time: 5.1028\n",
      "loss: 0.0005    f1: 0.8822    accuracy: 0.8813    precision: 0.8768    recall: 0.8919    time: 5.1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, vec):\n",
    "        x = self.relu(self.fc1(vec))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return torch.sigmoid(self.fc4(x))\n",
    "\n",
    "model = SimpleLinearModel().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "r = train(train_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"simple_linear_model\"] = {}\n",
    "results[\"simple_linear_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "r = train(train_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"simple_linear_model\"][\"title\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Convolution Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\toss: 0.3553    f1: 0.1232    accuracy: 0.4986    precision: 0.4313    recall: 0.0767    time: 5.35855\n",
      "loss: 0.3296    f1: 0.1233    accuracy: 0.4988    precision: 0.4311    recall: 0.0767    time: 5.4083\n",
      "\n",
      "[========================================] 100%\toss: 0.3475    f1: 0.2036    accuracy: 0.5159    precision: 0.5182    recall: 0.1451    time: 5.39000\n",
      "loss: 0.4132    f1: 0.2063    accuracy: 0.5162    precision: 0.5190    recall: 0.1479    time: 5.4374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SimpleConvolutionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvolutionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.conv = nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.conv(x.unsqueeze(1))\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.squeeze()\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleConvolutionModel().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "results[\"simple_convolution_model\"] = {}\n",
    "\n",
    "r = train(train_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"simple_convolution_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "r = train(train_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"simple_convolution_model\"][\"text\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Using a support vector machine (SVM) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def svm(X_train_data, y_train_data, X_test_data, y_test_data):\n",
    "    X_train = X_train_data.tolist()\n",
    "    X_test = X_test_data.tolist()\n",
    "    start_time = time.time()\n",
    "    clf = SVC(kernel='rbf')\n",
    "    print(\"fitting...\")\n",
    "    clf.fit(X_train,y_train_data)\n",
    "    print(\"predicting...\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return 0, f1_score(y_test_data,y_pred), accuracy_score(y_test_data, y_pred), precision_score(y_test_data, y_pred), recall_score(y_test_data, y_pred), time.time()-start_time\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting...\n"
     ]
    }
   ],
   "source": [
    "r = svm(X_train_text, y_train_text, X_test_text, y_test_text)\n",
    "loss, f1_score_text, accuracy_text, precision_text, recall_text, time_text = r\n",
    "print(\"Accuracy for text: {:.2f}%\\nF1 score for text: {:.2f}%\\nPrecision score for text: {:.2f}%\\nRecall score for text: {:.2f}%\".format(accuracy_text*100, f1_score_text*100, precision_text*100, recall_text*100))\n",
    "results[\"support_vector_machine\"] = {}\n",
    "results[\"support_vector_machine\"][\"text\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r = svm(X_train_title, y_train_title, X_test_title, y_test_title)\n",
    "loss, f1_score_title, accuracy_title, precision_title, recall_title, time_title = r\n",
    "print(\"Accuracy for title: {:.2f}%\\nF1 score for title: {:.2f}%\\nPrecision score for title: {:.2f}%\\nRecall score for title: {:.2f}%\".format(accuracy_title*100, f1_score_title*100, precision_title*100, recall_title*100))\n",
    "results[\"support_vector_machine\"][\"title\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Algorithm\n",
    "\n",
    "Using the random forest algorithm (RF) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test, name, crit='gini'):\n",
    "    start_time = time.time()\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, random_state = 42, verbose=0, n_jobs=-1, criterion=crit)\n",
    "    rf.fit(X_train.tolist(), y_train.tolist())\n",
    "    y_pred = rf.predict(X_test.tolist())\n",
    "    acc = accuracy_score(y_test.tolist(), y_pred)\n",
    "    f1 = f1_score(y_test.tolist(), y_pred)\n",
    "    prec = precision_score(y_test.tolist(), y_pred)\n",
    "    rec = recall_score(y_test.tolist(), y_pred)\n",
    "    print(\"accuracy for random forest with {} criterion {}: {:.2f}%\".format(crit, name, acc*100))\n",
    "    print(\"f1 score for random forest with {} criterion{}: {:.2f}%\".format(crit, name, f1*100))\n",
    "    print(\"precision score random forest with {} criterion for {}: {:.2f}%\".format(crit, name, prec*100))\n",
    "    print(\"recall score for random forest with {} criterion {}: {:.2f}%\".format(crit, name, rec*100))\n",
    "    return 0, f1, acc, prec, rec, time.time()-start_time\n",
    "\n",
    "results[\"random_forest\"] = {}\n",
    "r = random_forest(X_train_text, X_test_text, y_train_text, y_test_text, \"w2v text\")\n",
    "results[\"random_forest\"][\"text\"] = createDictElement(r)\n",
    "r = random_forest(X_train_title, X_test_title, y_train_title, y_test_title, \"w2v title\")\n",
    "results[\"random_forest\"][\"title\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "def pca_(X_test, y_test):\n",
    "    pca = PCA()\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('pca', pca)])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    Xt = pipe.fit_transform(X_test.tolist())\n",
    "    plot = plt.scatter(Xt[:,0], Xt[:,1], c=y_test.tolist(), alpha=0.6, s=0.9, cmap='plasma')\n",
    "    plt.legend(handles=plot.legend_elements()[0], labels=[\"real news\", \"fake_news\"])\n",
    "    plt.show()\n",
    "\n",
    "pca_(X_test_text, y_test_text)\n",
    "pca_(X_test_title, y_test_title)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
