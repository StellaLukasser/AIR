{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIR Project\n",
    "## Group 17\n",
    "\n",
    "We are using a dataset which includes non-fake as well as fake news (labeled dataset).\n",
    "https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os.path\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryRecall, BinaryPrecision, BinaryAccuracy\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detecting Fake News via PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running models with cuda:0\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"running models with {}\".format(device))\n",
    "# device = 'cpu'\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.mkdir(\"figures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Result Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def createDictElement(r):\n",
    "    total_loss, f1, acc, prec, rec, time = r\n",
    "    tmp = {}\n",
    "    tmp[\"total_loss\"] = total_loss\n",
    "    tmp[\"f1_score\"] = f1\n",
    "    tmp[\"accuracy\"] = acc\n",
    "    tmp[\"precision\"] = prec\n",
    "    tmp[\"recall\"] = rec\n",
    "    tmp[\"time\"] = time\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of dataset and nan-removal\n",
    "Result is saved in data/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process():\n",
    "    data = pd.read_csv('WELFake_Dataset.csv', index_col=0)\n",
    "    # display(data[:300])\n",
    "    for i,x in data.iterrows():\n",
    "        if len(str(x[\"text\"])) <= 10:\n",
    "            data.loc[i, \"text\"] = np.nan\n",
    "        if len(str(x[\"title\"])) <= 10:\n",
    "            data.loc[i, \"title\"] = np.nan\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.to_csv(\"data/data.csv\")\n",
    "    display(data[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data.csv\"):\n",
    "    pre_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Result is saved in data/data_token.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize():\n",
    "    stop = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    punc = [u'\\u201c',u'\\u201d',u'\\u2018',u'\\u2019',u'\\u2024',u'\\u2025',u'\\u2026',u'\\u2027']\n",
    "    # print(punc)\n",
    "    data = pd.read_csv('data/data.csv', index_col=0)\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    for i, row in data.iterrows():\n",
    "        title = str(row[\"title\"])\n",
    "        text = str(row[\"text\"])\n",
    "        t1 = \"\"\n",
    "        for c in title:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t1 += c\n",
    "            else:\n",
    "                t1 += \" \"\n",
    "        t2 = \"\"\n",
    "        for c in text:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t2 += c\n",
    "            else:\n",
    "                t2 += \" \"\n",
    "        title_tokens = nltk.tokenize.word_tokenize(t1)\n",
    "        text_tokens = nltk.tokenize.word_tokenize(t2)\n",
    "        # title_filtered = [w.lower() for w in title_tokens if not w.lower() in string.punctuation]\n",
    "        # title_filtered = [w.lower() for w in title_filtered if not w.lower() in punc]\n",
    "        title_filtered = [w.lower() for w in title_tokens if not w.lower() in stop]\n",
    "        title_stemmed = [stemmer.stem(w) for w in title_filtered]\n",
    "        # text_filtered = [w.lower() for w in text_tokens if not w.lower() in string.punctuation]\n",
    "        # text_filtered = [w.lower() for w in text_filtered if not w.lower() in punc]\n",
    "        text_filtered = [w.lower() for w in text_tokens if not w.lower() in stop]\n",
    "        text_stemmed = [stemmer.stem(w) for w in text_filtered]\n",
    "        # print(title_stemmed)\n",
    "        # print(text_stemmed)\n",
    "        titles.append(title_stemmed)\n",
    "        texts.append(text_stemmed)\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_cleaned = pd.DataFrame(data=d)\n",
    "    # data_cleaned[\"title\"] = titles\n",
    "    # data_cleaned[\"text\"] = texts\n",
    "    data_cleaned.to_csv(\"data/data_token.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_token.csv\"):\n",
    "    tokenize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    bow = []\n",
    "    bow_title = []\n",
    "    bow_text = []\n",
    "    bow_both = []\n",
    "    for i, row in data.iterrows():\n",
    "        words = row[\"title\"].split(\",\")\n",
    "        title = []\n",
    "        for word in words:\n",
    "            title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        words = row[\"text\"].split(\",\")\n",
    "        text = []\n",
    "        for word in words:\n",
    "            text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        dic_title = {}\n",
    "        dic_text = {}\n",
    "        dic_both = {}\n",
    "        for word in title:\n",
    "            if word in dic_title:\n",
    "                dic_title[word] = dic_title[word] + 1\n",
    "            else:\n",
    "                dic_title[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        for word in text:\n",
    "            if word in dic_text:\n",
    "                dic_text[word] = dic_text[word] + 1\n",
    "            else:\n",
    "                dic_text[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        bow_text.append(dic_text)\n",
    "        bow_title.append(dic_title)\n",
    "        bow_both.append(dic_both)\n",
    "    bow.append(bow_title)\n",
    "    bow.append(bow_text)\n",
    "    bow.append(bow_both)\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow = [bow_title[],bow_text[],bow_both[]]\n",
    "# bow = make_bow('data_tokenized/data_token.csv') # was uncommented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF with Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(bow_):\n",
    "    tf_ = []\n",
    "    for dic in bow_:\n",
    "        max_ = 0\n",
    "        for i in dic:\n",
    "            if dic[i] > max_:\n",
    "                max_ = dic[i]\n",
    "        tf_dic = {}\n",
    "        for word in dic:\n",
    "            tf_dic[word] = dic[word]/max_\n",
    "        tf_.append(tf_dic)\n",
    "    return tf_\n",
    "\n",
    "def idf(bow_):\n",
    "    df_ = {}\n",
    "    for dic in bow_:\n",
    "        for word in dic:\n",
    "            if word in df_:\n",
    "                df_[word] += 1\n",
    "            else:\n",
    "                df_[word] = 1\n",
    "    idf_ = {}\n",
    "    for word in df_:\n",
    "        idf_[word] = math.log10(len(bow)/df_[word])\n",
    "    return idf_\n",
    "\n",
    "def tf_idf(bow_):\n",
    "    tf_ = tf(bow_)\n",
    "    idf_ = idf(bow_)\n",
    "    tfidf = []\n",
    "    for dic in tf_:\n",
    "        tfidf_dic = {}\n",
    "        for word in dic:\n",
    "            tfidf_dic[word] = dic[word] * idf_[word]\n",
    "        tfidf.append(tfidf_dic)\n",
    "    return tfidf\n",
    "\n",
    "def cosineSim(dic_a, dic_b):\n",
    "    for word in dic_a:\n",
    "        if word not in dic_b:\n",
    "            dic_b[word] = 0\n",
    "    for word in dic_b:\n",
    "        if word not in dic_a:\n",
    "            dic_a[word] = 0\n",
    "    dot, sum_a, sum_b = 0,0,0\n",
    "    for word in dic_a:\n",
    "        a = dic_a[word]\n",
    "        b = dic_b[word]\n",
    "        dot += (a*b)\n",
    "        sum_a += math.pow(a,2)\n",
    "        sum_b += math.pow(b,2)\n",
    "    sqrt_sum_a = math.sqrt(sum_a)\n",
    "    sqrt_sum_b = math.sqrt(sum_b)\n",
    "    return dot / (sqrt_sum_a * sqrt_sum_b)\n",
    "\n",
    "def tfidf_cosine_ranking(word_, bow_):\n",
    "    tfidf_all = tf_idf(bow_)\n",
    "    list_query = [{word_: 1}]\n",
    "    tfidf_query = tf_idf(list_query)[0]\n",
    "    article_index = []\n",
    "    cosSim = []\n",
    "    cos_index = 0\n",
    "    for a in tfidf_all:\n",
    "        article_index.append(cos_index)\n",
    "        cosSim.append(cosineSim(a,tfidf_query))\n",
    "        cos_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': cosSim }).sort_values(by=['value'], ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cos_rank = tfidf_cosine_ranking('obama',bow[2])\n",
    "#print(cos_rank.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_ranking(query_,index_):\n",
    "    data = pd.read_csv('data_tokenized/data_token.csv', index_col=0)\n",
    "    corpus = []\n",
    "    title = []\n",
    "    text = []\n",
    "    both = []\n",
    "    for i, row in data.iterrows():\n",
    "            words = row[\"title\"].split(\",\")\n",
    "            for word in words:\n",
    "                title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "            words = row[\"text\"].split(\",\")\n",
    "            for word in words:\n",
    "                text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    if index_ == 0:\n",
    "        corpus = title\n",
    "    elif index_ == 1:\n",
    "        corpus = text\n",
    "    else:\n",
    "        for i in title:\n",
    "            both.append(title + text)\n",
    "        corpus = both\n",
    "\n",
    "    print(\"Starting bm25\")\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "    bm25_scores = bm25.get_scores(query_.split(\" \"))\n",
    "\n",
    "    article_index = []\n",
    "    bm25_index = 0\n",
    "    for a in bm25_scores:\n",
    "        article_index.append(bm25_index)\n",
    "        bm25_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': bm25_scores }).sort_values(by=['value'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25_rank = bm25_ranking('sunday',bow[2]) # was uncommented\n",
    "# print(bm25_rank.head(5)) # was uncommented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disc.\n"
     ]
    }
   ],
   "source": [
    "load_model_from_disc = True\n",
    "w2v_model = None\n",
    "data = pd.read_csv('data/data_token.csv', index_col=0)\n",
    "# for i, row in data.iterrows():\n",
    "#     print(type(row[\"title\"]))\n",
    "#     print(row)\n",
    "#     data.loc[i, \"title\"] = ast.literal_eval(row[\"title\"])\n",
    "#     data.loc[i, \"text\"] = ast.literal_eval(row[\"text\"])\n",
    "if load_model_from_disc:\n",
    "    try:\n",
    "        w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if w2v_model is None or not load_model_from_disc:\n",
    "    if load_model_from_disc:\n",
    "        print(\"Could not load model from disc. Training model...\")\n",
    "    else:\n",
    "        print(\"Loading from disc deactivated. Training model...\")\n",
    "\n",
    "    class MySentences(object):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def __iter__(self):\n",
    "            for doc in pd.concat([data[\"text\"], data[\"title\"]]): #change to \"title\" or combine both\n",
    "                doc = ast.literal_eval(doc)\n",
    "                yield doc\n",
    "\n",
    "    sentences = MySentences(data)\n",
    "\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(min_count=20,\n",
    "                         window=2,\n",
    "                         sample=6e-5,\n",
    "                         alpha=0.03,\n",
    "                         min_alpha=0.0007,\n",
    "                         negative=20,\n",
    "                         workers=cores-1)\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    t = time.time()\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=3, report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time.time() - t) / 60, 2)))\n",
    "    w2v_model.save(\"word2vec.model\")\n",
    "else:\n",
    "    print(\"Model loaded from disc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-0.08037868"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"amazon\", 'nazi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.61272305"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"obama\", 'trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'amazon'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out which element doesn't match\n",
    "w2v_model.wv.doesnt_match(['amazon', 'obama', 'trump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.5892792344093323),\n ('presid', 0.4774280786514282),\n ('outgo', 0.4366210401058197)]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which word is to obama as georg is to bush?\n",
    "w2v_model.wv.most_similar(positive=[\"obama\", \"georg\"], negative=[\"bush\"], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.8094509243965149),\n ('presid', 0.664080798625946),\n ('administr', 0.6274117231369019),\n ('predecessor', 0.6216334700584412),\n ('trump', 0.6127229928970337),\n ('undo', 0.5917911529541016),\n ('outgo', 0.5659363865852356),\n ('bush', 0.5520379543304443),\n ('michell', 0.5356377959251404),\n ('bachelet', 0.5156714916229248)]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"obama\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('obama', 0.664080798625946),\n ('barack', 0.6538994908332825),\n ('45th', 0.6537858843803406),\n ('trump', 0.6239981651306152),\n ('predecessor', 0.6086247563362122),\n ('donald', 0.6058627963066101),\n ('administr', 0.5998252630233765),\n ('presidenti', 0.5920149087905884),\n ('outgo', 0.5902089476585388),\n ('successor', 0.5844656825065613)]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"presid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Doc2Vec\n",
    "word2vec for each word with average over document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates w2v representation for all documents and titles\n",
    "def doc2vec():\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    start = time.time()\n",
    "    for i, row in data.iterrows():\n",
    "        vec_title = np.zeros(shape=w2v_model.vector_size)\n",
    "        vec_text = np.zeros(shape=w2v_model.vector_size)\n",
    "        tit = ast.literal_eval(row[\"title\"])\n",
    "        tex = ast.literal_eval(row[\"text\"])\n",
    "        tit_cnt = 0\n",
    "        tex_cnt = 0\n",
    "        for word in tit:\n",
    "            try:\n",
    "                vec_title += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tit_cnt += 1\n",
    "                pass\n",
    "        for word in tex:\n",
    "            try:\n",
    "                vec_text += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tex_cnt += 1\n",
    "                pass\n",
    "        if len(tit) > tit_cnt:\n",
    "            vec_title /= (len(tit) - tit_cnt)\n",
    "        if len(tex) > tex_cnt:\n",
    "            vec_text /= (len(tex) - tex_cnt)\n",
    "        titles.append(vec_title.tolist())\n",
    "        texts.append(vec_text.tolist())\n",
    "        if i % 5000 == 0:\n",
    "            print(\"[{}/{}] - {:.1f}s\".format(i, len(data.index), time.time() - start))\n",
    "    end = time.time()\n",
    "    print(\"creating doc2vec took {:.1f}s\".format(end - start))\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_w2v = pd.DataFrame(data=d)\n",
    "    data_w2v.to_pickle(\"data/data_w2v.pkl\")\n",
    "    display(data_w2v[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_w2v.pkl\"):\n",
    "    doc2vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-split and Dataloader Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels = list()\n",
    "    texts = list()\n",
    "    for (_text, _label) in batch:\n",
    "        labels.append(_label)\n",
    "        texts.append(_text)\n",
    "\n",
    "    return torch.tensor(texts), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "batch_size = 100\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'collate_fn': collate_batch,\n",
    "          'drop_last': True}\n",
    "\n",
    "\n",
    "data_d2v = pd.read_pickle(\"data/data_w2v.pkl\")\n",
    "\n",
    "data_d2v_title = data_d2v[[\"title\", \"label\"]].copy()\n",
    "data_d2v_text = data_d2v[[\"text\", \"label\"]].copy()\n",
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(data_d2v_title[\"title\"], data_d2v_title[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(data_d2v_text[\"text\"], data_d2v_text[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "\n",
    "X_train_title.reset_index(drop=True, inplace=True)\n",
    "X_test_title.reset_index(drop=True, inplace=True)\n",
    "y_train_title.reset_index(drop=True, inplace=True)\n",
    "y_test_title.reset_index(drop=True, inplace=True)\n",
    "X_train_text.reset_index(drop=True, inplace=True)\n",
    "X_test_text.reset_index(drop=True, inplace=True)\n",
    "y_train_text.reset_index(drop=True, inplace=True)\n",
    "y_test_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "class data_set(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(Dataset, self).__init__()\n",
    "        assert len(X.index) == len(y.index)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "train_dataset_title = data_set(X_train_title, y_train_title)\n",
    "test_dataset_title = data_set(X_test_title, y_test_title)\n",
    "train_dataset_text = data_set(X_train_text, y_train_text)\n",
    "test_dataset_text = data_set(X_test_text, y_test_text)\n",
    "\n",
    "train_dataloader_title = DataLoader(train_dataset_title, **params)\n",
    "test_dataloader_title = DataLoader(test_dataset_title, **params)\n",
    "train_dataloader_text = DataLoader(train_dataset_text, **params)\n",
    "test_dataloader_text = DataLoader(test_dataset_text, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Progress Bar and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics_to_log(log, metrics, y_true, y_pred, prefix=''):\n",
    "    for metric in metrics:\n",
    "        q = metric(y_true, y_pred)\n",
    "        log[prefix + metric.__name__] = q\n",
    "    return\n",
    "\n",
    "def log_to_message(log, precision=4):\n",
    "    fmt = \"{0}: {1:.\" + str(precision) + \"f}\"\n",
    "    return \"    \".join(fmt.format(k, v) for k, v in log.items())\n",
    "\n",
    "class ProgressBar(object):\n",
    "    \"\"\"Cheers @ajratner\"\"\"\n",
    "\n",
    "    def __init__(self, n, length=40):\n",
    "        # Protect against division by zero\n",
    "        self.n      = max(1, n)\n",
    "        self.nf     = float(n)\n",
    "        self.length = length\n",
    "        # Precalculate the i values that should trigger a write operation\n",
    "        self.ticks = set([round(i/100.0 * n) for i in range(101)])\n",
    "        self.ticks.add(n-1)\n",
    "        self.bar(0)\n",
    "\n",
    "    def bar(self, i, message=\"\"):\n",
    "        \"\"\"Assumes i ranges through [0, n-1]\"\"\"\n",
    "        if i in self.ticks:\n",
    "            b = int(np.ceil(((i+1) / self.nf) * self.length))\n",
    "            sys.stdout.write(\"\\r[{0}{1}] {2}%\\t{3}\".format(\n",
    "                \"=\"*b, \" \"*(self.length-b), int(100*((i+1) / self.nf)), message\n",
    "            ))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    def close(self, message=\"\"):\n",
    "        # Move the bar to 100% before closing\n",
    "        self.bar(self.n-1)\n",
    "        sys.stdout.write(\"\\n{0}\\n\\n\".format(message))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    start_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    f1 = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    accuracy = 0\n",
    "    f1_score_ = BinaryF1Score().to(device)\n",
    "    precision_ = BinaryPrecision().to(device)\n",
    "    recall_ = BinaryRecall().to(device)\n",
    "    accuracy_ = BinaryAccuracy().to(device)\n",
    "    pb = ProgressBar(size/batch_size)\n",
    "    log = OrderedDict()\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.squeeze(), y.float())\n",
    "        total_loss += loss.item()\n",
    "        f1 += f1_score_(pred.squeeze(), y)\n",
    "        precision += precision_(pred.squeeze(), y)\n",
    "        recall += recall_(pred.squeeze(), y)\n",
    "        accuracy += accuracy_(pred.squeeze(), y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        log['loss'] = float(loss) / (batch + 1)\n",
    "        log['f1'] = float(f1) / (batch + 1)\n",
    "        log['accuracy'] = float(accuracy) / (batch + 1) #correct / ((batch + 1) * batch_size)\n",
    "        log['precision'] = float(precision) / (batch + 1)\n",
    "        log['recall'] = float(recall) / (batch + 1)\n",
    "        log['time'] = time.time() - start_time\n",
    "        pb.bar(batch, log_to_message(log))\n",
    "    pb.close(log_to_message(log))\n",
    "    return total_loss, (f1/num_batches).item(), (accuracy/num_batches).item(), (precision/num_batches).item(), (recall/num_batches).item(), time.time()-start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    start_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    f1 = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    accuracy = 0\n",
    "    f1_score_ = BinaryF1Score().to(device)\n",
    "    precision_ = BinaryPrecision().to(device)\n",
    "    recall_ = BinaryRecall().to(device)\n",
    "    accuracy_ = BinaryAccuracy().to(device)\n",
    "    pb = ProgressBar(size/batch_size)\n",
    "    log = OrderedDict()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred.squeeze(), y.float())\n",
    "            f1 += f1_score_(pred.squeeze(), y)\n",
    "            precision += precision_(pred.squeeze(), y)\n",
    "            recall += recall_(pred.squeeze(), y)\n",
    "            accuracy += accuracy_(pred.squeeze(), y)\n",
    "            # Backpropagation\n",
    "            log['loss'] = float(test_loss) / (batch + 1)\n",
    "            log['f1'] = float(f1) / (batch + 1)\n",
    "            log['accuracy'] = float(accuracy) / (batch + 1) #correct / ((batch + 1) * batch_size)\n",
    "            log['precision'] = float(precision) / (batch + 1)\n",
    "            log['recall'] = float(recall) / (batch + 1)\n",
    "            log['time'] = time.time() - start_time\n",
    "            pb.bar(batch, log_to_message(log))\n",
    "    pb.close(log_to_message(log))\n",
    "    return test_loss.item(), (f1/num_batches).item(), (accuracy/num_batches).item(), (precision/num_batches).item(), (recall/num_batches).item(), time.time()-start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_dataloader, test_dataloader, model, loss_fn, optimizer, training=True):\n",
    "    if training:\n",
    "        for i in range(epochs):\n",
    "            print(\"Epoch {}: ------------------------------------------------------------------------------------------------------------------------\".format(i+1))\n",
    "            train(train_dataloader, model, loss_fn, optimizer)\n",
    "    print(\"Evaluation ------------------------------------------------------------------------------------------------------------------------\")\n",
    "    return test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model for testing of training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8416    accuracy: 0.8469    precision: 0.8420    recall: 0.8482    time: 10.3095\n",
      "loss: 0.0005    f1: 0.8419    accuracy: 0.8471    precision: 0.8421    recall: 0.8486    time: 10.3780\n",
      "\n",
      "Epoch 2: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8766    accuracy: 0.8756    precision: 0.8716    recall: 0.8844    time: 9.1253\n",
      "loss: 0.0004    f1: 0.8765    accuracy: 0.8755    precision: 0.8713    recall: 0.8845    time: 9.1903\n",
      "\n",
      "Epoch 3: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8823    accuracy: 0.8814    precision: 0.8775    recall: 0.8900    time: 9.0543\n",
      "loss: 0.0003    f1: 0.8825    accuracy: 0.8816    precision: 0.8778    recall: 0.8901    time: 9.1257\n",
      "\n",
      "Epoch 4: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0006    f1: 0.8887    accuracy: 0.8881    precision: 0.8840    recall: 0.8960    time: 9.1101\n",
      "loss: 0.0004    f1: 0.8885    accuracy: 0.8879    precision: 0.8838    recall: 0.8959    time: 9.1863\n",
      "\n",
      "Epoch 5: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8942    accuracy: 0.8937    precision: 0.8900    recall: 0.9010    time: 9.0594\n",
      "loss: 0.0003    f1: 0.8944    accuracy: 0.8938    precision: 0.8900    recall: 0.9012    time: 9.1792\n",
      "\n",
      "Epoch 6: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8973    accuracy: 0.8966    precision: 0.8930    recall: 0.9043    time: 9.0490\n",
      "loss: 0.0003    f1: 0.8973    accuracy: 0.8966    precision: 0.8931    recall: 0.9042    time: 9.1121\n",
      "\n",
      "Epoch 7: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.9022    accuracy: 0.9015    precision: 0.8977    recall: 0.9091    time: 8.8923\n",
      "loss: 0.0003    f1: 0.9022    accuracy: 0.9015    precision: 0.8977    recall: 0.9091    time: 8.9776\n",
      "\n",
      "Epoch 8: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.9060    accuracy: 0.9055    precision: 0.9020    recall: 0.9123    time: 9.1427\n",
      "loss: 0.0003    f1: 0.9060    accuracy: 0.9056    precision: 0.9020    recall: 0.9124    time: 9.2102\n",
      "\n",
      "Epoch 9: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.9094    accuracy: 0.9091    precision: 0.9065    recall: 0.9146    time: 8.9142\n",
      "loss: 0.0003    f1: 0.9095    accuracy: 0.9091    precision: 0.9067    recall: 0.9145    time: 9.0285\n",
      "\n",
      "Epoch 10: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.9123    accuracy: 0.9120    precision: 0.9089    recall: 0.9179    time: 9.2969\n",
      "loss: 0.0004    f1: 0.9122    accuracy: 0.9119    precision: 0.9090    recall: 0.9177    time: 9.3704\n",
      "\n",
      "Evaluation ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.2640    f1: 0.8974    accuracy: 0.8965    precision: 0.8935    recall: 0.9037    time: 1.4470\n",
      "loss: 0.2640    f1: 0.8974    accuracy: 0.8965    precision: 0.8935    recall: 0.9037    time: 1.4470\n",
      "\n",
      "Epoch 1: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0006    f1: 0.8537    accuracy: 0.8616    precision: 0.8540    recall: 0.8619    time: 9.0727\n",
      "loss: 0.0005    f1: 0.8540    accuracy: 0.8618    precision: 0.8543    recall: 0.8621    time: 9.1632\n",
      "\n",
      "Epoch 2: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8907    accuracy: 0.8896    precision: 0.8839    recall: 0.9006    time: 9.0316\n",
      "loss: 0.0003    f1: 0.8908    accuracy: 0.8897    precision: 0.8838    recall: 0.9008    time: 9.1059\n",
      "\n",
      "Epoch 3: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8996    accuracy: 0.8991    precision: 0.8975    recall: 0.9049    time: 9.0185\n",
      "loss: 0.0004    f1: 0.8996    accuracy: 0.8991    precision: 0.8976    recall: 0.9048    time: 9.0912\n",
      "\n",
      "Epoch 4: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.9066    accuracy: 0.9063    precision: 0.9040    recall: 0.9121    time: 8.9708\n",
      "loss: 0.0003    f1: 0.9066    accuracy: 0.9062    precision: 0.9036    recall: 0.9123    time: 9.0488\n",
      "\n",
      "Epoch 5: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.9100    accuracy: 0.9098    precision: 0.9075    recall: 0.9151    time: 9.1333\n",
      "loss: 0.0005    f1: 0.9099    accuracy: 0.9096    precision: 0.9072    recall: 0.9152    time: 9.2089\n",
      "\n",
      "Epoch 6: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0003    f1: 0.9128    accuracy: 0.9128    precision: 0.9119    recall: 0.9165    time: 9.4867\n",
      "loss: 0.0005    f1: 0.9128    accuracy: 0.9126    precision: 0.9115    recall: 0.9167    time: 9.5555\n",
      "\n",
      "Epoch 7: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0003    f1: 0.9167    accuracy: 0.9165    precision: 0.9139    recall: 0.9218    time: 8.9724\n",
      "loss: 0.0003    f1: 0.9167    accuracy: 0.9165    precision: 0.9137    recall: 0.9221    time: 9.0445\n",
      "\n",
      "Epoch 8: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0003    f1: 0.9195    accuracy: 0.9193    precision: 0.9175    recall: 0.9237    time: 9.0788\n",
      "loss: 0.0005    f1: 0.9194    accuracy: 0.9190    precision: 0.9172    recall: 0.9237    time: 9.1449\n",
      "\n",
      "Epoch 9: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.9218    accuracy: 0.9217    precision: 0.9198    recall: 0.9260    time: 8.9889\n",
      "loss: 0.0004    f1: 0.9218    accuracy: 0.9216    precision: 0.9196    recall: 0.9262    time: 9.0554\n",
      "\n",
      "Epoch 10: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0003    f1: 0.9243    accuracy: 0.9239    precision: 0.9215    recall: 0.9290    time: 8.9940\n",
      "loss: 0.0005    f1: 0.9243    accuracy: 0.9239    precision: 0.9216    recall: 0.9291    time: 9.0987\n",
      "\n",
      "Evaluation ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.2151    f1: 0.9188    accuracy: 0.9194    precision: 0.9273    recall: 0.9119    time: 1.4161\n",
      "loss: 0.2151    f1: 0.9188    accuracy: 0.9194    precision: 0.9273    recall: 0.9119    time: 1.4161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, vec):\n",
    "        x = self.relu(self.fc1(vec))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return torch.sigmoid(self.fc4(x))\n",
    "\n",
    "model = SimpleLinearModel().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_title, test_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"simple_linear_model\"] = {}\n",
    "results[\"simple_linear_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "model = SimpleLinearModel().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_text, test_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"simple_linear_model\"][\"text\"] = createDictElement(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.4559    f1: 0.6688    accuracy: 0.5040    precision: 0.5040    recall: 0.9999    time: 11.0798\n",
      "loss: 0.4444    f1: 0.6691    accuracy: 0.5044    precision: 0.5044    recall: 0.9999    time: 11.1519\n",
      "\n",
      "Epoch 2: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3219    f1: 0.6494    accuracy: 0.5349    precision: 0.5271    recall: 0.8692    time: 8.57143\n",
      "loss: 0.3798    f1: 0.6494    accuracy: 0.5357    precision: 0.5278    recall: 0.8678    time: 8.6391\n",
      "\n",
      "Epoch 3: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3429    f1: 0.7408    accuracy: 0.7303    precision: 0.7166    recall: 0.7712    time: 8.55142\n",
      "loss: 0.3534    f1: 0.7413    accuracy: 0.7306    precision: 0.7168    recall: 0.7718    time: 8.6287\n",
      "\n",
      "Epoch 4: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.2759    f1: 0.7961    accuracy: 0.7890    precision: 0.7732    recall: 0.8247    time: 8.24598\n",
      "loss: 0.3899    f1: 0.7964    accuracy: 0.7893    precision: 0.7737    recall: 0.8249    time: 8.3068\n",
      "\n",
      "Epoch 5: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3864    f1: 0.8106    accuracy: 0.8043    precision: 0.7884    recall: 0.8375    time: 8.48585\n",
      "loss: 0.4044    f1: 0.8107    accuracy: 0.8044    precision: 0.7885    recall: 0.8376    time: 8.5604\n",
      "\n",
      "Epoch 6: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3584    f1: 0.8274    accuracy: 0.8224    precision: 0.8077    recall: 0.8510    time: 8.36551\n",
      "loss: 0.3877    f1: 0.8275    accuracy: 0.8225    precision: 0.8078    recall: 0.8510    time: 8.4289\n",
      "\n",
      "Epoch 7: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3146    f1: 0.8410    accuracy: 0.8369    precision: 0.8216    recall: 0.8644    time: 8.44030\n",
      "loss: 0.4102    f1: 0.8412    accuracy: 0.8370    precision: 0.8219    recall: 0.8644    time: 8.5121\n",
      "\n",
      "Epoch 8: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3900    f1: 0.8515    accuracy: 0.8475    precision: 0.8323    recall: 0.8746    time: 8.55982\n",
      "loss: 0.3790    f1: 0.8515    accuracy: 0.8475    precision: 0.8326    recall: 0.8744    time: 8.6250\n",
      "\n",
      "Epoch 9: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3885    f1: 0.8579    accuracy: 0.8546    precision: 0.8408    recall: 0.8783    time: 8.56861\n",
      "loss: 0.4162    f1: 0.8581    accuracy: 0.8546    precision: 0.8410    recall: 0.8784    time: 8.6335\n",
      "\n",
      "Epoch 10: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3796    f1: 0.8626    accuracy: 0.8588    precision: 0.8424    recall: 0.8867    time: 8.39649\n",
      "loss: 0.3608    f1: 0.8628    accuracy: 0.8590    precision: 0.8424    recall: 0.8869    time: 8.4589\n",
      "\n",
      "Evaluation ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 221.4593    f1: 0.8624    accuracy: 0.8601    precision: 0.8544    recall: 0.8722    time: 1.8998\n",
      "loss: 221.4593    f1: 0.8624    accuracy: 0.8601    precision: 0.8544    recall: 0.8722    time: 1.8998\n",
      "\n",
      "Epoch 1: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.4558    f1: 0.6234    accuracy: 0.5040    precision: 0.5050    recall: 0.8210    time: 8.42702\n",
      "loss: 0.3679    f1: 0.6234    accuracy: 0.5039    precision: 0.5049    recall: 0.8213    time: 8.4834\n",
      "\n",
      "Epoch 2: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3631    f1: 0.6600    accuracy: 0.5046    precision: 0.5045    recall: 0.9609    time: 8.27071\n",
      "loss: 0.3678    f1: 0.6600    accuracy: 0.5046    precision: 0.5045    recall: 0.9609    time: 8.3288\n",
      "\n",
      "Epoch 3: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.2986    f1: 0.6507    accuracy: 0.5843    precision: 0.5766    recall: 0.7810    time: 8.35257\n",
      "loss: 0.3961    f1: 0.6513    accuracy: 0.5852    precision: 0.5778    recall: 0.7806    time: 8.4609\n",
      "\n",
      "Epoch 4: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.4030    f1: 0.7739    accuracy: 0.7629    precision: 0.7432    recall: 0.8123    time: 8.28583\n",
      "loss: 0.3895    f1: 0.7744    accuracy: 0.7634    precision: 0.7440    recall: 0.8124    time: 8.3947\n",
      "\n",
      "Epoch 5: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3572    f1: 0.8214    accuracy: 0.8152    precision: 0.7991    recall: 0.8491    time: 8.74156\n",
      "loss: 0.3116    f1: 0.8212    accuracy: 0.8151    precision: 0.7987    recall: 0.8490    time: 8.8395\n",
      "\n",
      "Epoch 6: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3054    f1: 0.8354    accuracy: 0.8305    precision: 0.8143    recall: 0.8612    time: 8.79403\n",
      "loss: 0.3233    f1: 0.8355    accuracy: 0.8307    precision: 0.8144    recall: 0.8613    time: 8.8574\n",
      "\n",
      "Epoch 7: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3946    f1: 0.8478    accuracy: 0.8431    precision: 0.8253    recall: 0.8752    time: 8.39834\n",
      "loss: 0.4149    f1: 0.8477    accuracy: 0.8430    precision: 0.8255    recall: 0.8749    time: 8.5061\n",
      "\n",
      "Epoch 8: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3611    f1: 0.8579    accuracy: 0.8538    precision: 0.8372    recall: 0.8832    time: 8.33532\n",
      "loss: 0.2851    f1: 0.8578    accuracy: 0.8537    precision: 0.8369    recall: 0.8833    time: 8.4404\n",
      "\n",
      "Epoch 9: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.4319    f1: 0.8654    accuracy: 0.8615    precision: 0.8436    recall: 0.8915    time: 8.51452\n",
      "loss: 0.3169    f1: 0.8654    accuracy: 0.8616    precision: 0.8435    recall: 0.8916    time: 8.6153\n",
      "\n",
      "Epoch 10: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3279    f1: 0.8679    accuracy: 0.8644    precision: 0.8494    recall: 0.8905    time: 8.80259\n",
      "loss: 0.4183    f1: 0.8679    accuracy: 0.8644    precision: 0.8495    recall: 0.8903    time: 8.9277\n",
      "\n",
      "Evaluation ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 221.2232    f1: 0.8668    accuracy: 0.8644    precision: 0.8581    recall: 0.8780    time: 1.6509\n",
      "loss: 221.2232    f1: 0.8668    accuracy: 0.8644    precision: 0.8581    recall: 0.8780    time: 1.6509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SimpleConvolutionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvolutionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, 100)\n",
    "        self.conv = nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.conv(x.unsqueeze(1))\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.squeeze()\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleConvolutionModel().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "results[\"simple_convolution_model\"] = {}\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_title, test_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"simple_convolution_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "model = SimpleConvolutionModel().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "#\n",
    "r = train_and_evaluate(train_dataloader_text, test_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"simple_convolution_model\"][\"text\"] = createDictElement(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM model with convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0012    f1: 0.4959    accuracy: 0.4988    precision: 0.4736    recall: 0.6322    time: 14.4270\n",
      "loss: 0.0012    f1: 0.4973    accuracy: 0.4988    precision: 0.4738    recall: 0.6349    time: 14.5408\n",
      "\n",
      "Epoch 2: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0012    f1: 0.5578    accuracy: 0.5012    precision: 0.4841    recall: 0.7693    time: 13.8794\n",
      "loss: 0.0012    f1: 0.5583    accuracy: 0.5008    precision: 0.4838    recall: 0.7712    time: 13.9892\n",
      "\n",
      "Epoch 3: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0009    f1: 0.6105    accuracy: 0.6349    precision: 0.6060    recall: 0.6424    time: 13.8585\n",
      "loss: 0.0008    f1: 0.6117    accuracy: 0.6361    precision: 0.6073    recall: 0.6434    time: 13.9640\n",
      "\n",
      "Epoch 4: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0007    f1: 0.7979    accuracy: 0.7967    precision: 0.7956    recall: 0.8048    time: 13.9756\n",
      "loss: 0.0007    f1: 0.7980    accuracy: 0.7968    precision: 0.7958    recall: 0.8047    time: 14.0791\n",
      "\n",
      "Epoch 5: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8342    accuracy: 0.8332    precision: 0.8299    recall: 0.8415    time: 13.6076\n",
      "loss: 0.0005    f1: 0.8345    accuracy: 0.8334    precision: 0.8303    recall: 0.8415    time: 13.7383\n",
      "\n",
      "Epoch 6: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0006    f1: 0.8494    accuracy: 0.8482    precision: 0.8446    recall: 0.8573    time: 13.8183\n",
      "loss: 0.0007    f1: 0.8495    accuracy: 0.8481    precision: 0.8447    recall: 0.8572    time: 13.9376\n",
      "\n",
      "Epoch 7: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8582    accuracy: 0.8566    precision: 0.8520    recall: 0.8673    time: 14.1673\n",
      "loss: 0.0007    f1: 0.8582    accuracy: 0.8567    precision: 0.8521    recall: 0.8672    time: 14.2883\n",
      "\n",
      "Epoch 8: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0006    f1: 0.8648    accuracy: 0.8636    precision: 0.8578    recall: 0.8753    time: 44.1754\n",
      "loss: 0.0004    f1: 0.8648    accuracy: 0.8636    precision: 0.8580    recall: 0.8752    time: 44.2845\n",
      "\n",
      "Epoch 9: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8691    accuracy: 0.8676    precision: 0.8619    recall: 0.8788    time: 14.5572\n",
      "loss: 0.0004    f1: 0.8691    accuracy: 0.8676    precision: 0.8619    recall: 0.8790    time: 14.6756\n",
      "\n",
      "Epoch 10: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8721    accuracy: 0.8705    precision: 0.8650    recall: 0.8818    time: 13.9809\n",
      "loss: 0.0003    f1: 0.8724    accuracy: 0.8707    precision: 0.8652    recall: 0.8820    time: 14.1015\n",
      "\n",
      "Evaluation ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.3046    f1: 0.8726    accuracy: 0.8706    precision: 0.8679    recall: 0.8798    time: 1.5613\n",
      "loss: 0.3046    f1: 0.8726    accuracy: 0.8706    precision: 0.8679    recall: 0.8798    time: 1.5613\n",
      "\n",
      "Epoch 1: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0012    f1: 0.4224    accuracy: 0.5014    precision: 0.4268    recall: 0.5666    time: 13.9859\n",
      "loss: 0.0012    f1: 0.4243    accuracy: 0.5013    precision: 0.4273    recall: 0.5697    time: 14.1074\n",
      "\n",
      "Epoch 2: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0010    f1: 0.6135    accuracy: 0.6033    precision: 0.6085    recall: 0.6729    time: 13.9092\n",
      "loss: 0.0008    f1: 0.6148    accuracy: 0.6043    precision: 0.6093    recall: 0.6743    time: 14.0376\n",
      "\n",
      "Epoch 3: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0006    f1: 0.7996    accuracy: 0.7978    precision: 0.7963    recall: 0.8073    time: 14.5821\n",
      "loss: 0.0009    f1: 0.7996    accuracy: 0.7979    precision: 0.7961    recall: 0.8075    time: 14.6997\n",
      "\n",
      "Epoch 4: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0007    f1: 0.8491    accuracy: 0.8470    precision: 0.8411    recall: 0.8605    time: 13.9675\n",
      "loss: 0.0006    f1: 0.8491    accuracy: 0.8470    precision: 0.8410    recall: 0.8605    time: 14.0829\n",
      "\n",
      "Epoch 5: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8612    accuracy: 0.8598    precision: 0.8557    recall: 0.8699    time: 13.8212\n",
      "loss: 0.0006    f1: 0.8610    accuracy: 0.8597    precision: 0.8554    recall: 0.8699    time: 13.9272\n",
      "\n",
      "Epoch 6: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8723    accuracy: 0.8707    precision: 0.8646    recall: 0.8831    time: 14.0336\n",
      "loss: 0.0006    f1: 0.8722    accuracy: 0.8706    precision: 0.8647    recall: 0.8829    time: 14.1557\n",
      "\n",
      "Epoch 7: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0006    f1: 0.8760    accuracy: 0.8751    precision: 0.8715    recall: 0.8834    time: 13.9801\n",
      "loss: 0.0004    f1: 0.8760    accuracy: 0.8750    precision: 0.8715    recall: 0.8834    time: 14.0997\n",
      "\n",
      "Epoch 8: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8837    accuracy: 0.8828    precision: 0.8792    recall: 0.8905    time: 13.7332\n",
      "loss: 0.0004    f1: 0.8838    accuracy: 0.8829    precision: 0.8795    recall: 0.8904    time: 13.8619\n",
      "\n",
      "Epoch 9: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0005    f1: 0.8873    accuracy: 0.8868    precision: 0.8857    recall: 0.8915    time: 16.1663\n",
      "loss: 0.0004    f1: 0.8874    accuracy: 0.8869    precision: 0.8860    recall: 0.8915    time: 16.3185\n",
      "\n",
      "Epoch 10: ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.0004    f1: 0.8924    accuracy: 0.8920    precision: 0.8911    recall: 0.8961    time: 20.0361\n",
      "loss: 0.0004    f1: 0.8925    accuracy: 0.8921    precision: 0.8912    recall: 0.8962    time: 20.2130\n",
      "\n",
      "Evaluation ------------------------------------------------------------------------------------------------------------------------\n",
      "[========================================] 100%\toss: 0.2607    f1: 0.8904    accuracy: 0.8910    precision: 0.9028    recall: 0.8799    time: 2.3066\n",
      "loss: 0.2607    f1: 0.8904    accuracy: 0.8910    precision: 0.9028    recall: 0.8799    time: 2.3066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, 100)\n",
    "        # self.embed = nn.Embedding(\n",
    "        #     num_embeddings=len(w2v_model.wv),\n",
    "        #     embedding_dim=100)\n",
    "        self.conv = nn.Conv1d(in_channels=100, out_channels=100, kernel_size=6, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "        # self.fc2 = nn.Linear(95, 1)\n",
    "        self.lstm = nn.LSTM(96, 32, 3, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(self.conv(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.squeeze()\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = LSTM().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "results[\"lstm_model\"] = {}\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_title, test_dataloader_title, model, loss_fn, optimizer)\n",
    "results[\"lstm_model\"][\"title\"] = createDictElement(r)\n",
    "\n",
    "model = LSTM().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "r = train_and_evaluate(train_dataloader_text, test_dataloader_text, model, loss_fn, optimizer)\n",
    "results[\"lstm_model\"][\"text\"] = createDictElement(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Using a support vector machine (SVM) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_train_data, y_train_data, X_test_data, y_test_data):\n",
    "    X_train = X_train_data.tolist()\n",
    "    X_test = X_test_data.tolist()\n",
    "    start_time = time.time()\n",
    "    clf = SVC(kernel='rbf')\n",
    "    print(\"fitting...\")\n",
    "    clf.fit(X_train,y_train_data)\n",
    "    print(\"predicting...\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return 0, f1_score(y_test_data,y_pred), accuracy_score(y_test_data, y_pred), precision_score(y_test_data, y_pred), recall_score(y_test_data, y_pred), time.time()-start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting...\n"
     ]
    }
   ],
   "source": [
    "r = svm(X_train_text, y_train_text, X_test_text, y_test_text)\n",
    "loss, f1_score_text, accuracy_text, precision_text, recall_text, time_text = r\n",
    "print(\"Accuracy for text: {:.2f}%\\nF1 score for text: {:.2f}%\\nPrecision score for text: {:.2f}%\\nRecall score for text: {:.2f}%\".format(accuracy_text*100, f1_score_text*100, precision_text*100, recall_text*100))\n",
    "results[\"support_vector_machine\"] = {}\n",
    "results[\"support_vector_machine\"][\"text\"] = createDictElement(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "r = svm(X_train_title, y_train_title, X_test_title, y_test_title)\n",
    "loss, f1_score_title, accuracy_title, precision_title, recall_title, time_title = r\n",
    "print(\"Accuracy for title: {:.2f}%\\nF1 score for title: {:.2f}%\\nPrecision score for title: {:.2f}%\\nRecall score for title: {:.2f}%\".format(accuracy_title*100, f1_score_title*100, precision_title*100, recall_title*100))\n",
    "results[\"support_vector_machine\"][\"title\"] = createDictElement(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm\n",
    "\n",
    "Using the random forest algorithm (RF) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test, name, crit='gini'):\n",
    "    start_time = time.time()\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, random_state = 42, verbose=0, n_jobs=-1, criterion=crit)\n",
    "    rf.fit(X_train.tolist(), y_train.tolist())\n",
    "    y_pred = rf.predict(X_test.tolist())\n",
    "    acc = accuracy_score(y_test.tolist(), y_pred)\n",
    "    f1 = f1_score(y_test.tolist(), y_pred)\n",
    "    prec = precision_score(y_test.tolist(), y_pred)\n",
    "    rec = recall_score(y_test.tolist(), y_pred)\n",
    "    print(\"accuracy for random forest with {} criterion {}: {:.2f}%\".format(crit, name, acc*100))\n",
    "    print(\"f1 score for random forest with {} criterion{}: {:.2f}%\".format(crit, name, f1*100))\n",
    "    print(\"precision score random forest with {} criterion for {}: {:.2f}%\".format(crit, name, prec*100))\n",
    "    print(\"recall score for random forest with {} criterion {}: {:.2f}%\".format(crit, name, rec*100))\n",
    "    return 0, f1, acc, prec, rec, time.time()-start_time\n",
    "\n",
    "results[\"random_forest\"] = {}\n",
    "r = random_forest(X_train_text, X_test_text, y_train_text, y_test_text, \"w2v text\")\n",
    "results[\"random_forest\"][\"text\"] = createDictElement(r)\n",
    "r = random_forest(X_train_title, X_test_title, y_train_title, y_test_title, \"w2v title\")\n",
    "results[\"random_forest\"][\"title\"] = createDictElement(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Passive Aggressive Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def detect_news(column_name, df):\n",
    "    labels=df.label\n",
    "    x_train,x_test,y_train,y_test=train_test_split(df[column_name], labels, test_size=0.15, random_state=7)\n",
    "\n",
    "    # Initialize a TfidfVectorizer\n",
    "    tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.9)\n",
    "\n",
    "    # Fit and transform train set, transform test set\n",
    "    tfidf_train=tfidf_vectorizer.fit_transform(x_train)\n",
    "    tfidf_test=tfidf_vectorizer.transform(x_test)\n",
    "\n",
    "    # Initialize a PassiveAggressiveClassifier\n",
    "    pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "    start_time = time.time()\n",
    "    pac.fit(tfidf_train,y_train)\n",
    "    time_ = time.time() - start_time\n",
    "\n",
    "    # Predict on the test set and calculate accuracy\n",
    "    y_pred=pac.predict(tfidf_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    prec = precision_score(y_test,y_pred)\n",
    "    rec = recall_score(y_test,y_pred)\n",
    "    print(f'Accuracy {column_name}: {round(acc*100,2)}%')\n",
    "\n",
    "    # Build confusion matrix\n",
    "    results = confusion_matrix(y_test,y_pred, labels=[1,0])\n",
    "\n",
    "    print(f'Results {column_name}: \\n true positives: {results[0][0]}\\n false negatives: {results[0][1]}\\n false positives: {results[1][0]}\\n true negatives {results[1][1]}\\n')\n",
    "\n",
    "    return 0, acc, f1, prec, rec, time_\n",
    "\n",
    "df=pd.read_csv('data/data.csv')\n",
    "\n",
    "results[\"passive_aggressive\"] = {}\n",
    "r = detect_news('text', df)\n",
    "results[\"passive_aggressive\"][\"text\"] = createDictElement(r)\n",
    "r = detect_news('title', df)\n",
    "results[\"passive_aggressive\"][\"title\"] = createDictElement(r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prinicipal Component Analysis\n",
    "\n",
    "### PCA is done to be able to display the distribution of the real and fake news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def pca_(X_test, y_test, name):\n",
    "    pca = PCA()\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('pca', pca)])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    Xt = pipe.fit_transform(X_test.tolist())\n",
    "    plot = plt.scatter(Xt[:,0], Xt[:,1], c=y_test.tolist(), alpha=0.6, s=0.9, cmap='PiYG')\n",
    "    plt.legend(handles=plot.legend_elements()[0], labels=[\"real news\", \"fake news\"])\n",
    "    plt.suptitle(\"PCA of all {}s\".format(name))\n",
    "    plt.savefig(\"figures/pca_{}.png\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pca_(X_test_text, y_test_text, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pca_(X_test_title, y_test_title, \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds\n",
    "\n",
    "### Word Clouds of the most common words are created to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def wc(label):\n",
    "    data_pre = pd.read_csv(\"data_tokenized/data_token_no_stem.csv\", index_col=0)\n",
    "    data_pre_real = data_pre.loc[data_pre[\"label\"] == label]\n",
    "    data_pre = None\n",
    "    x = \"\"\n",
    "    for i, vals in data_pre_real.iterrows():\n",
    "        for val in ast.literal_eval(vals[\"title\"]):\n",
    "            x += \" \"\n",
    "            x += val\n",
    "        # if i % 1000 == 0:\n",
    "        #     print(i)\n",
    "\n",
    "    wordcloud = WordCloud(max_font_size=100, max_words=75, background_color=\"white\", width=600, height=400, colormap='tab20b').generate(x)\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.savefig(\"figures/word_cloud_{}.png\".format(\"real\" if label == 1 else \"fake\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wc(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wc(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Occurences of real and fake news articles plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_pre = pd.read_csv(\"data_tokenized/data_token_no_stem.csv\", index_col=0)\n",
    "data_pre_real = len(data_pre.loc[data_pre[\"label\"] == 1].index)\n",
    "data_pre_fake = len(data_pre.loc[data_pre[\"label\"] == 0].index)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(0, data_pre_real)\n",
    "ax.bar_label(bars)\n",
    "bars = ax.bar(1, data_pre_fake)\n",
    "ax.bar_label(bars)\n",
    "ax.set_ylim(25000, 40000)\n",
    "ax.set_xticks([])\n",
    "plt.suptitle(\"Number of occurences of real and fake news articles\")\n",
    "plt.legend(labels=[\"real news\", \"fake news\"])\n",
    "plt.savefig(\"figures/num_of_occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results\n",
    "### Compare Scores between algorithms (F1-Score and Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 8})\n",
    "fig, ax = plt.subplots(2, figsize=(8,8))\n",
    "plt.suptitle(\"F1-score and accuracy of the different algorithms\")\n",
    "width = 0.3  # the width of the bars\n",
    "\n",
    "def setSubplots1(input, axis_x):\n",
    "    ax[axis_x].set_ylim(0.8, 1.0)\n",
    "    algorithms = []\n",
    "    f1s = []\n",
    "    accs = []\n",
    "    for element in results:\n",
    "        algorithms.append(element)\n",
    "        f1s.append(round(results[element][input][\"f1_score\"],4))\n",
    "        accs.append(round(results[element][input][\"accuracy\"],4))\n",
    "\n",
    "    x = np.arange(len(algorithms))  # the label locations\n",
    "\n",
    "    rects1 = ax[axis_x].bar(x - width/2, f1s, width, label='F1-Score')\n",
    "    rects2 = ax[axis_x].bar(x + width/2, accs, width, label='Accuracy')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax[axis_x].set_ylabel('Scores')\n",
    "    ax[axis_x].set_title(input + ' input')\n",
    "    ax[axis_x].set_xticks(x, algorithms)\n",
    "    ax[axis_x].legend()\n",
    "\n",
    "    ax[axis_x].bar_label(rects1, padding=3)\n",
    "    ax[axis_x].bar_label(rects2, padding=3)\n",
    "\n",
    "setSubplots1(\"text\", 0)\n",
    "setSubplots1(\"title\", 1)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures/Comparison_algorithms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare scores between different inputs (text and title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scores = [\"f1_score\", \"accuracy\", \"precision\", \"recall\"]\n",
    "x = np.arange(len(scores))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "fig, ax = plt.subplots(3, 2, figsize=(16,8))\n",
    "plt.suptitle(\"Scores for tet and title input\")\n",
    "\n",
    "def setSubplot(algorithm, axis_x, axis_y):\n",
    "    title_values = []\n",
    "    text_values = []\n",
    "    for element in results[algorithm][\"text\"]:\n",
    "        text_values.append(round(results[algorithm][\"text\"][element],4))\n",
    "    for element in results[algorithm][\"title\"]:\n",
    "        title_values.append(round(results[algorithm][\"title\"][element],4))\n",
    "    title_values.pop()\n",
    "    text_values.pop()\n",
    "    title_values.pop(0)\n",
    "    text_values.pop(0)\n",
    "\n",
    "    rects1 = ax[axis_x][axis_y].bar(x - width/2, text_values, width, label='Text')\n",
    "    rects2 = ax[axis_x][axis_y].bar(x + width/2, title_values, width, label='Title')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax[axis_x][axis_y].set_ylabel('Scores')\n",
    "    ax[axis_x][axis_y].set_title(algorithm)\n",
    "    ax[axis_x][axis_y].set_xticks(x, scores)\n",
    "    ax[axis_x][axis_y].legend()\n",
    "\n",
    "    ax[axis_x][axis_y].bar_label(rects1, padding=3)\n",
    "    ax[axis_x][axis_y].bar_label(rects2, padding=3)\n",
    "    ax[axis_x][axis_y].set_ylim(0.7, 1.0)\n",
    "\n",
    "setSubplot(\"simple_linear_model\", 0, 0)\n",
    "setSubplot(\"simple_convolution_model\", 0, 1)\n",
    "setSubplot(\"support_vector_machine\", 1, 0)\n",
    "setSubplot(\"random_forest\", 1, 1)\n",
    "setSubplot(\"lstm_model\", 2, 0)\n",
    "setSubplot(\"passive_aggressive\", 2, 1)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\"figures/Comparison_input\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
