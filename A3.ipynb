{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def pre_process():\n",
    "    data = pd.read_csv('WELFake_Dataset.csv', index_col=0)\n",
    "    print(data.shape)\n",
    "    # display(data[:300])\n",
    "    for i,x in data.iterrows():\n",
    "        if len(str(x[\"text\"])) <= 10:\n",
    "            data.loc[i, \"text\"] = np.nan\n",
    "        if len(str(x[\"title\"])) <= 10:\n",
    "            data.loc[i, \"title\"] = np.nan\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    print(data.shape)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.to_csv(\"data/data.csv\")\n",
    "    display(data[:300])\n",
    "\n",
    "def tokenize():\n",
    "    stop = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    punc = [u'\\u201c',u'\\u201d',u'\\u2018',u'\\u2019',u'\\u2024',u'\\u2025',u'\\u2026',u'\\u2027']\n",
    "    print(punc)\n",
    "    data = pd.read_csv('data/data.csv', index_col=0)\n",
    "    data_cleaned = data.copy()\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    for i, row in data.iterrows():\n",
    "        title = str(row[\"title\"])\n",
    "        text = str(row[\"text\"])\n",
    "        t1 = \"\"\n",
    "        for c in title:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t1 += c\n",
    "            else:\n",
    "                t1 += \" \"\n",
    "        t2 = \"\"\n",
    "        for c in text:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t2 += c\n",
    "            else:\n",
    "                t2 += \" \"\n",
    "        title_tokens = nltk.tokenize.word_tokenize(t1)\n",
    "        text_tokens = nltk.tokenize.word_tokenize(t2)\n",
    "        # title_filtered = [w.lower() for w in title_tokens if not w.lower() in string.punctuation]\n",
    "        # title_filtered = [w.lower() for w in title_filtered if not w.lower() in punc]\n",
    "        title_filtered = [w.lower() for w in title_tokens if not w.lower() in stop]\n",
    "        title_stemmed = [stemmer.stem(w) for w in title_filtered]\n",
    "        # text_filtered = [w.lower() for w in text_tokens if not w.lower() in string.punctuation]\n",
    "        # text_filtered = [w.lower() for w in text_filtered if not w.lower() in punc]\n",
    "        text_filtered = [w.lower() for w in text_tokens if not w.lower() in stop]\n",
    "        text_stemmed = [stemmer.stem(w) for w in text_filtered]\n",
    "        # print(title_stemmed)\n",
    "        # print(text_stemmed)\n",
    "        titles.append(title_stemmed)\n",
    "        texts.append(text_stemmed)\n",
    "    data_cleaned[\"title\"] = titles\n",
    "    data_cleaned[\"text\"] = texts\n",
    "    data_cleaned.to_csv(\"data/data_token.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bag of Words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def make_bow(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    bow = []\n",
    "    for title,text,_ in data:\n",
    "        dic_title = {}\n",
    "        dic_text = {}\n",
    "        dic_both = {}\n",
    "        for word in title:\n",
    "            if word in dic_title:\n",
    "                dic_title[word] = dic_title[word] + 1\n",
    "            else:\n",
    "                dic_title[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        for word in text:\n",
    "            if word in dic_title:\n",
    "                dic_title[word] = dic_title[word] + 1\n",
    "            else:\n",
    "                dic_title[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        bow.append([dic_title,dic_text,dic_both])\n",
    "    return bow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bow = [[bow_title,bow_text,bow_both],[bow_title,bow_text,bow_both]...]\n",
    "bow = make_bow('data/data_token.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TFIDF with Cosine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import math\n",
    "def tf(bow_,index_):\n",
    "    tf_ = []\n",
    "    for dic in bow_:\n",
    "        max_ = 0\n",
    "        for i in dic[index_]:\n",
    "            if dic[index_][i] > max_:\n",
    "                max_ = dic[index_][i]\n",
    "\n",
    "        tf_dic = {}\n",
    "        for word in dic[index_]:\n",
    "            tf_dic[word] = dic[index_][word]/max_\n",
    "        tf_.append(tf_dic)\n",
    "    return tf_\n",
    "\n",
    "def idf(bow_,index_):\n",
    "    df_ = {}\n",
    "    for dic in bow_:\n",
    "        for word in dic[index_]:\n",
    "            if word in df_:\n",
    "                df_[word] += 1\n",
    "            else:\n",
    "                df_[word] = 1\n",
    "    idf_ = {}\n",
    "    for word in df_:\n",
    "        idf_[word] = math.log10(len(bow)/df_[word])\n",
    "    return idf_\n",
    "def tf_idf(bow_, index_):\n",
    "    tf_ = tf(bow_, index_)\n",
    "    idf_ = idf(bow_, index_)\n",
    "    tfidf = []\n",
    "    for dic in tf_:\n",
    "        tfidf_dic = {}\n",
    "        for word in dic:\n",
    "            tfidf_dic[word] = dic[word] * idf_[word]\n",
    "        tfidf.append(tfidf_dic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_idf_ = tf_idf(bow,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}