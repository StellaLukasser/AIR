{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AIR Project\n",
    "## Group 17\n",
    "\n",
    "We are using a dataset which includes non-fake as well as fake news (labeled dataset).\n",
    "https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports and specific settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "outputs": [],
   "source": [
    "import ast\n",
    "import os.path\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running models with cuda:0\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"running models with {}\".format(device))\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading of dataset and nan-removal\n",
    "Uncomment function-call to redo preprocessing\n",
    "Result is saved in data/data.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "outputs": [],
   "source": [
    "def pre_process():\n",
    "    data = pd.read_csv('WELFake_Dataset.csv', index_col=0)\n",
    "    # display(data[:300])\n",
    "    for i,x in data.iterrows():\n",
    "        if len(str(x[\"text\"])) <= 10:\n",
    "            data.loc[i, \"text\"] = np.nan\n",
    "        if len(str(x[\"title\"])) <= 10:\n",
    "            data.loc[i, \"title\"] = np.nan\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.to_csv(\"data/data.csv\")\n",
    "    display(data[:300])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data.csv\"):\n",
    "    pre_process()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization\n",
    "Uncomment function-call to redo tokenization for data/data.csv\n",
    "Result is saved in data/data_token.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "outputs": [],
   "source": [
    "def tokenize():\n",
    "    stop = stopwords.words('english')\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    punc = [u'\\u201c',u'\\u201d',u'\\u2018',u'\\u2019',u'\\u2024',u'\\u2025',u'\\u2026',u'\\u2027']\n",
    "    # print(punc)\n",
    "    data = pd.read_csv('data/data.csv', index_col=0)\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    for i, row in data.iterrows():\n",
    "        title = str(row[\"title\"])\n",
    "        text = str(row[\"text\"])\n",
    "        t1 = \"\"\n",
    "        for c in title:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t1 += c\n",
    "            else:\n",
    "                t1 += \" \"\n",
    "        t2 = \"\"\n",
    "        for c in text:\n",
    "            if not (c in string.punctuation or c in punc):\n",
    "                t2 += c\n",
    "            else:\n",
    "                t2 += \" \"\n",
    "        title_tokens = nltk.tokenize.word_tokenize(t1)\n",
    "        text_tokens = nltk.tokenize.word_tokenize(t2)\n",
    "        # title_filtered = [w.lower() for w in title_tokens if not w.lower() in string.punctuation]\n",
    "        # title_filtered = [w.lower() for w in title_filtered if not w.lower() in punc]\n",
    "        title_filtered = [w.lower() for w in title_tokens if not w.lower() in stop]\n",
    "        title_stemmed = [stemmer.stem(w) for w in title_filtered]\n",
    "        # text_filtered = [w.lower() for w in text_tokens if not w.lower() in string.punctuation]\n",
    "        # text_filtered = [w.lower() for w in text_filtered if not w.lower() in punc]\n",
    "        text_filtered = [w.lower() for w in text_tokens if not w.lower() in stop]\n",
    "        text_stemmed = [stemmer.stem(w) for w in text_filtered]\n",
    "        # print(title_stemmed)\n",
    "        # print(text_stemmed)\n",
    "        titles.append(title_stemmed)\n",
    "        texts.append(text_stemmed)\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_cleaned = pd.DataFrame(data=d)\n",
    "    # data_cleaned[\"title\"] = titles\n",
    "    # data_cleaned[\"text\"] = texts\n",
    "    data_cleaned.to_csv(\"data/data_token.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_token.csv\"):\n",
    "    tokenize()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of Words\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "outputs": [],
   "source": [
    "def make_bow(data_path):\n",
    "    data = pd.read_csv(data_path, index_col=0)\n",
    "    bow = []\n",
    "    bow_title = []\n",
    "    bow_text = []\n",
    "    bow_both = []\n",
    "    for i, row in data.iterrows():\n",
    "        words = row[\"title\"].split(\",\")\n",
    "        title = []\n",
    "        for word in words:\n",
    "            title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        words = row[\"text\"].split(\",\")\n",
    "        text = []\n",
    "        for word in words:\n",
    "            text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "        dic_title = {}\n",
    "        dic_text = {}\n",
    "        dic_both = {}\n",
    "        for word in title:\n",
    "            if word in dic_title:\n",
    "                dic_title[word] = dic_title[word] + 1\n",
    "            else:\n",
    "                dic_title[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        for word in text:\n",
    "            if word in dic_text:\n",
    "                dic_text[word] = dic_text[word] + 1\n",
    "            else:\n",
    "                dic_text[word] = 1\n",
    "            if word in dic_both:\n",
    "                dic_both[word] = dic_both[word] + 1\n",
    "            else:\n",
    "                dic_both[word] = 1\n",
    "        bow_text.append(dic_text)\n",
    "        bow_title.append(dic_title)\n",
    "        bow_both.append(dic_both)\n",
    "    bow.append(bow_title)\n",
    "    bow.append(bow_text)\n",
    "    bow.append(bow_both)\n",
    "    return bow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "outputs": [],
   "source": [
    "# bow = [bow_title[],bow_text[],bow_both[]]\n",
    "# bow = make_bow('data_tokenized/data_token.csv') # was uncommented"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TFIDF with Cosine"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "outputs": [],
   "source": [
    "def tf(bow_):\n",
    "    tf_ = []\n",
    "    for dic in bow_:\n",
    "        max_ = 0\n",
    "        for i in dic:\n",
    "            if dic[i] > max_:\n",
    "                max_ = dic[i]\n",
    "        tf_dic = {}\n",
    "        for word in dic:\n",
    "            tf_dic[word] = dic[word]/max_\n",
    "        tf_.append(tf_dic)\n",
    "    return tf_\n",
    "\n",
    "def idf(bow_):\n",
    "    df_ = {}\n",
    "    for dic in bow_:\n",
    "        for word in dic:\n",
    "            if word in df_:\n",
    "                df_[word] += 1\n",
    "            else:\n",
    "                df_[word] = 1\n",
    "    idf_ = {}\n",
    "    for word in df_:\n",
    "        idf_[word] = math.log10(len(bow)/df_[word])\n",
    "    return idf_\n",
    "\n",
    "def tf_idf(bow_):\n",
    "    tf_ = tf(bow_)\n",
    "    idf_ = idf(bow_)\n",
    "    tfidf = []\n",
    "    for dic in tf_:\n",
    "        tfidf_dic = {}\n",
    "        for word in dic:\n",
    "            tfidf_dic[word] = dic[word] * idf_[word]\n",
    "        tfidf.append(tfidf_dic)\n",
    "    return tfidf\n",
    "\n",
    "def cosineSim(dic_a, dic_b):\n",
    "    for word in dic_a:\n",
    "        if word not in dic_b:\n",
    "            dic_b[word] = 0\n",
    "    for word in dic_b:\n",
    "        if word not in dic_a:\n",
    "            dic_a[word] = 0\n",
    "    dot, sum_a, sum_b = 0,0,0\n",
    "    for word in dic_a:\n",
    "        a = dic_a[word]\n",
    "        b = dic_b[word]\n",
    "        dot += (a*b)\n",
    "        sum_a += math.pow(a,2)\n",
    "        sum_b += math.pow(b,2)\n",
    "    sqrt_sum_a = math.sqrt(sum_a)\n",
    "    sqrt_sum_b = math.sqrt(sum_b)\n",
    "    return dot / (sqrt_sum_a * sqrt_sum_b)\n",
    "\n",
    "def tfidf_cosine_ranking(word_, bow_):\n",
    "    tfidf_all = tf_idf(bow_)\n",
    "    list_query = [{word_: 1}]\n",
    "    tfidf_query = tf_idf(list_query)[0]\n",
    "    article_index = []\n",
    "    cosSim = []\n",
    "    cos_index = 0\n",
    "    for a in tfidf_all:\n",
    "        article_index.append(cos_index)\n",
    "        cosSim.append(cosineSim(a,tfidf_query))\n",
    "        cos_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': cosSim }).sort_values(by=['value'], ascending=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [],
   "source": [
    "#cos_rank = tfidf_cosine_ranking('obama',bow[2])\n",
    "#print(cos_rank.head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bm25"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "outputs": [],
   "source": [
    "def bm25_ranking(query_,index_):\n",
    "    data = pd.read_csv('data_tokenized/data_token.csv', index_col=0)\n",
    "    corpus = []\n",
    "    title = []\n",
    "    text = []\n",
    "    both = []\n",
    "    for i, row in data.iterrows():\n",
    "            words = row[\"title\"].split(\",\")\n",
    "            for word in words:\n",
    "                title.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "            words = row[\"text\"].split(\",\")\n",
    "            for word in words:\n",
    "                text.append(str(word).replace(\"'\", \"\").replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\"))\n",
    "    if index_ == 0:\n",
    "        corpus = title\n",
    "    elif index_ == 1:\n",
    "        corpus = text\n",
    "    else:\n",
    "        for i in title:\n",
    "            both.append(title + text)\n",
    "        corpus = both\n",
    "\n",
    "    print(\"Starting bm25\")\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "    bm25_scores = bm25.get_scores(query_.split(\" \"))\n",
    "\n",
    "    article_index = []\n",
    "    bm25_index = 0\n",
    "    for a in bm25_scores:\n",
    "        article_index.append(bm25_index)\n",
    "        bm25_index += 1\n",
    "    return pd.DataFrame({'article': article_index ,'value': bm25_scores }).sort_values(by=['value'], ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "outputs": [],
   "source": [
    "# bm25_rank = bm25_ranking('sunday',bow[2]) # was uncommented\n",
    "# print(bm25_rank.head(5)) # was uncommented"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating and Training Word2Vec Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from disc.\n"
     ]
    }
   ],
   "source": [
    "load_model_from_disc = True\n",
    "w2v_model = None\n",
    "data = pd.read_csv('data/data_token.csv', index_col=0)\n",
    "# for i, row in data.iterrows():\n",
    "#     print(type(row[\"title\"]))\n",
    "#     print(row)\n",
    "#     data.loc[i, \"title\"] = ast.literal_eval(row[\"title\"])\n",
    "#     data.loc[i, \"text\"] = ast.literal_eval(row[\"text\"])\n",
    "if load_model_from_disc:\n",
    "    try:\n",
    "        w2v_model = Word2Vec.load(\"word2vec.model\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if w2v_model is None or not load_model_from_disc:\n",
    "    if load_model_from_disc:\n",
    "        print(\"Could not load model from disc. Training model...\")\n",
    "    else:\n",
    "        print(\"Loading from disc deactivated. Training model...\")\n",
    "\n",
    "    class MySentences(object):\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "\n",
    "        def __iter__(self):\n",
    "            for doc in pd.concat([data[\"text\"], data[\"title\"]]): #change to \"title\" or combine both\n",
    "                doc = ast.literal_eval(doc)\n",
    "                yield doc\n",
    "\n",
    "    sentences = MySentences(data)\n",
    "\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    w2v_model = Word2Vec(min_count=20,\n",
    "                         window=2,\n",
    "                         sample=6e-5,\n",
    "                         alpha=0.03,\n",
    "                         min_alpha=0.0007,\n",
    "                         negative=20,\n",
    "                         workers=cores-1)\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    t = time.time()\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=3, report_delay=1)\n",
    "    print('Time to train the model: {} mins'.format(round((time.time() - t) / 60, 2)))\n",
    "    w2v_model.save(\"word2vec.model\")\n",
    "else:\n",
    "    print(\"Model loaded from disc.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.11904364"
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"amazon\", 'nazi')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "outputs": [
    {
     "data": {
      "text/plain": "0.60530704"
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate similarity\n",
    "w2v_model.wv.similarity(\"obama\", 'trump')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "outputs": [
    {
     "data": {
      "text/plain": "'amazon'"
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out which element doesn't match\n",
    "w2v_model.wv.doesnt_match(['amazon', 'obama', 'trump'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.607993483543396),\n ('presid', 0.4728606641292572),\n ('behest', 0.4636874198913574)]"
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which word is to obama as georg is to bush?\n",
    "w2v_model.wv.most_similar(positive=[\"obama\", \"georg\"], negative=[\"bush\"], topn=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.832769513130188),\n ('administr', 0.6584988832473755),\n ('presid', 0.6397863626480103),\n ('predecessor', 0.625878632068634),\n ('trump', 0.6053071022033691),\n ('bush', 0.557529628276825),\n ('outgo', 0.5535241961479187),\n ('undo', 0.5471165180206299),\n ('holdov', 0.5300476551055908),\n ('clinton', 0.5224902629852295)]"
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"obama\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "outputs": [
    {
     "data": {
      "text/plain": "[('barack', 0.7051833868026733),\n ('45th', 0.6659713387489319),\n ('successor', 0.6399291157722473),\n ('obama', 0.6397863626480103),\n ('administr', 0.6288126111030579),\n ('trump', 0.6117547750473022),\n ('donald', 0.6109979748725891),\n ('predecessor', 0.6096833348274231),\n ('pres', 0.594482958316803),\n ('presidenti', 0.5868942737579346)]"
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. words most similar to obama\n",
    "w2v_model.wv.most_similar(positive=[\"presid\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Doc2Vec\n",
    "word2vec for each word with average over document"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "outputs": [],
   "source": [
    "# creates w2v representation for all documents and titles\n",
    "def doc2vec():\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    start = time.time()\n",
    "    for i, row in data.iterrows():\n",
    "        vec_title = np.zeros(shape=w2v_model.vector_size)\n",
    "        vec_text = np.zeros(shape=w2v_model.vector_size)\n",
    "        tit = ast.literal_eval(row[\"title\"])\n",
    "        tex = ast.literal_eval(row[\"text\"])\n",
    "        tit_cnt = 0\n",
    "        tex_cnt = 0\n",
    "        for word in tit:\n",
    "            try:\n",
    "                vec_title += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tit_cnt += 1\n",
    "                pass\n",
    "        for word in tex:\n",
    "            try:\n",
    "                vec_text += w2v_model.wv[word]\n",
    "            except KeyError:\n",
    "                # print(\"Didn't find word {}\".format(word))\n",
    "                tex_cnt += 1\n",
    "                pass\n",
    "        if len(tit) > tit_cnt:\n",
    "            vec_title /= (len(tit) - tit_cnt)\n",
    "        if len(tex) > tex_cnt:\n",
    "            vec_text /= (len(tex) - tex_cnt)\n",
    "        titles.append(vec_title.tolist())\n",
    "        texts.append(vec_text.tolist())\n",
    "        if i % 5000 == 0:\n",
    "            print(\"[{}/{}] - {:.1f}s\".format(i, len(data.index), time.time() - start))\n",
    "    end = time.time()\n",
    "    print(\"creating doc2vec took {:.1f}s\".format(end - start))\n",
    "    d = {\"title\":titles, \"text\":texts, \"label\":data[\"label\"]}\n",
    "    data_w2v = pd.DataFrame(data=d)\n",
    "    data_w2v.to_pickle(\"data/data_w2v.pkl\")\n",
    "    display(data_w2v[:100])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/data_w2v.pkl\"):\n",
    "    doc2vec()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test-split and Dataloader Creation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    labels = list()\n",
    "    texts = list()\n",
    "    for (_text, _label) in batch:\n",
    "        labels.append(_label)\n",
    "        texts.append(_text)\n",
    "\n",
    "    return torch.tensor(texts), torch.tensor(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'collate_fn': collate_batch,\n",
    "          'drop_last': True}\n",
    "\n",
    "\n",
    "data_d2v = pd.read_pickle(\"data/data_w2v.pkl\")\n",
    "titles = list()\n",
    "texts = list()\n",
    "# print(\"interpreting data\")\n",
    "# for i, row in data_d2v.iterrows():\n",
    "#     titles.append(ast.literal_eval(row[\"title\"]))\n",
    "#     texts.append(ast.literal_eval(row[\"text\"]))\n",
    "# print(\"done interpreting data\")\n",
    "# data_d2v[\"title\"] = titles\n",
    "# data_d2v[\"text\"] = texts\n",
    "\n",
    "data_d2v_title = data_d2v[[\"title\", \"label\"]].copy()\n",
    "data_d2v_text = data_d2v[[\"text\", \"label\"]].copy()\n",
    "X_train_title, X_test_title, y_train_title, y_test_title = train_test_split(data_d2v_title[\"title\"], data_d2v_title[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(data_d2v_text[\"text\"], data_d2v_text[\"label\"], test_size=0.15, random_state=42, shuffle=True)\n",
    "\n",
    "X_train_title.reset_index(drop=True, inplace=True)\n",
    "X_test_title.reset_index(drop=True, inplace=True)\n",
    "y_train_title.reset_index(drop=True, inplace=True)\n",
    "y_test_title.reset_index(drop=True, inplace=True)\n",
    "X_train_text.reset_index(drop=True, inplace=True)\n",
    "X_test_text.reset_index(drop=True, inplace=True)\n",
    "y_train_text.reset_index(drop=True, inplace=True)\n",
    "y_test_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "class data_set(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(Dataset, self).__init__()\n",
    "        assert len(X.index) == len(y.index)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "train_dataset_title = data_set(X_train_title, y_train_title)\n",
    "test_dataset_title = data_set(X_test_title, y_test_title)\n",
    "train_dataset_text = data_set(X_train_text, y_train_text)\n",
    "test_dataset_text = data_set(X_test_text, y_test_text)\n",
    "\n",
    "train_dataloader_title = DataLoader(train_dataset_title, **params)\n",
    "test_dataloader_title = DataLoader(test_dataset_title, **params)\n",
    "train_dataloader_text = DataLoader(train_dataset_text, **params)\n",
    "test_dataloader_text = DataLoader(test_dataset_text, **params)\n",
    "\n",
    "for batch, (X, y) in enumerate(train_dataloader_title):\n",
    "    # print(X)\n",
    "    # print(X.shape)\n",
    "    # print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "outputs": [],
   "source": [
    "def add_metrics_to_log(log, metrics, y_true, y_pred, prefix=''):\n",
    "    for metric in metrics:\n",
    "        q = metric(y_true, y_pred)\n",
    "        log[prefix + metric.__name__] = q\n",
    "    return\n",
    "\n",
    "def log_to_message(log, precision=4):\n",
    "    fmt = \"{0}: {1:.\" + str(precision) + \"f}\"\n",
    "    return \"    \".join(fmt.format(k, v) for k, v in log.items())\n",
    "\n",
    "class ProgressBar(object):\n",
    "    \"\"\"Cheers @ajratner\"\"\"\n",
    "\n",
    "    def __init__(self, n, length=40):\n",
    "        # Protect against division by zero\n",
    "        self.n      = max(1, n)\n",
    "        self.nf     = float(n)\n",
    "        self.length = length\n",
    "        # Precalculate the i values that should trigger a write operation\n",
    "        self.ticks = set([round(i/100.0 * n) for i in range(101)])\n",
    "        self.ticks.add(n-1)\n",
    "        self.bar(0)\n",
    "\n",
    "    def bar(self, i, message=\"\"):\n",
    "        \"\"\"Assumes i ranges through [0, n-1]\"\"\"\n",
    "        if i in self.ticks:\n",
    "            b = int(np.ceil(((i+1) / self.nf) * self.length))\n",
    "            sys.stdout.write(\"\\r[{0}{1}] {2}%\\t{3}\".format(\n",
    "                \"=\"*b, \" \"*(self.length-b), int(100*((i+1) / self.nf)), message\n",
    "            ))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    def close(self, message=\"\"):\n",
    "        # Move the bar to 100% before closing\n",
    "        self.bar(self.n-1)\n",
    "        sys.stdout.write(\"\\n{0}\\n\\n\".format(message))\n",
    "        sys.stdout.flush()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    start_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    f1 = 0\n",
    "    correct = 0\n",
    "    f1_score = BinaryF1Score().to(device)\n",
    "    pb = ProgressBar(size/batch_size)\n",
    "    log = OrderedDict()\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.squeeze(), y.float())\n",
    "        total_loss += loss.item()\n",
    "        f1 += f1_score(pred.squeeze(), y)\n",
    "        correct += (pred.squeeze().int() == y).float().sum()\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        log['loss'] = float(loss) / (batch + 1)\n",
    "        log['f1'] = float(f1) / (batch + 1)\n",
    "        log['accuracy'] = correct / ((batch + 1) * batch_size)\n",
    "        log['time'] = time.time() - start_time\n",
    "        pb.bar(batch, log_to_message(log))\n",
    "    pb.close(log_to_message(log))\n",
    "    return total_loss, (f1/num_batches).item(), (correct/(num_batches*batch_size)).item(), time.time()-start_time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Model for testing of training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "outputs": [],
   "source": [
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, vec):\n",
    "        x = self.relu(self.fc1(vec))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        return torch.sigmoid(self.fc4(x))\n",
    "\n",
    "model = SimpleLinearModel().to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train(train_dataloader_title, model, loss_fn, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next steps:\n",
    "\n",
    "Save tfidf in csv file @Freddy\n",
    "Use tfidf as input for Dataloader creation (in comparison to w2v as input) @Freddy\n",
    "Design new models, e.g.: using convolution/decision-trees #TODO @everybody who wants to\n",
    "Presentation/Visualization of data and results @everybody who wants to"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "outputs": [],
   "source": [
    "class SimpleConvolutionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvolutionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.conv = nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.conv(x.unsqueeze(1))\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.squeeze()\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleConvolutionModel()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "train(train_dataloader_title, model, loss_fn, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Using a support vector machine (SVM) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "outputs": [],
   "source": [
    "def svg(X_train_data, y_train_data, X_test_data, y_test_data):\n",
    "    X_train = X_train_data.tolist()\n",
    "    X_test = X_test_data.tolist()\n",
    "\n",
    "    clf = SVC(kernel='linear')\n",
    "    print(\"fitting...\")\n",
    "    clf.fit(X_train,y_train_data)\n",
    "    print(\"predicting...\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test_data, y_pred), f1_score(y_test_data,y_pred), precision_score(y_test_data, y_pred), recall_score(y_test_data, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[584], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m accuracy_text, f1_score_text, precision_text, recall_text \u001B[38;5;241m=\u001B[39m \u001B[43msvg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy for text: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mF1 score for text: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mPrecision score for text: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mRecall score for text: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(accuracy_text\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m, f1_score_text\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m, precision_text\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m, recall_text\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m))\n",
      "Cell \u001B[1;32mIn[583], line 7\u001B[0m, in \u001B[0;36msvg\u001B[1;34m(X_train_data, y_train_data, X_test_data, y_test_data)\u001B[0m\n\u001B[0;32m      5\u001B[0m clf \u001B[38;5;241m=\u001B[39m SVC(kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfitting...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredicting...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:251\u001B[0m, in \u001B[0;36mBaseLibSVM.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LibSVM]\u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    250\u001B[0m seed \u001B[38;5;241m=\u001B[39m rnd\u001B[38;5;241m.\u001B[39mrandint(np\u001B[38;5;241m.\u001B[39miinfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmax)\n\u001B[1;32m--> 251\u001B[0m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001B[39;00m\n\u001B[0;32m    254\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_ \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m (n_samples,)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:333\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_fit\u001B[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001B[0m\n\u001B[0;32m    319\u001B[0m libsvm\u001B[38;5;241m.\u001B[39mset_verbosity_wrap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[0;32m    321\u001B[0m \u001B[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001B[39;00m\n\u001B[0;32m    322\u001B[0m \u001B[38;5;66;03m# add other parameters to __init__\u001B[39;00m\n\u001B[0;32m    323\u001B[0m (\n\u001B[0;32m    324\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_,\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_vectors_,\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_support,\n\u001B[0;32m    327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual_coef_,\n\u001B[0;32m    328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_,\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probA,\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probB,\n\u001B[0;32m    331\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_status_,\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_iter,\n\u001B[1;32m--> 333\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[43mlibsvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43mC\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprobability\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobability\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshrinking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshrinking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warn_from_fit_status()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_text, f1_score_text, precision_text, recall_text = svg(X_train_text, y_train_text, X_test_text, y_test_text)\n",
    "print(\"Accuracy for text: {:.2f}%\\nF1 score for text: {:.2f}%\\nPrecision score for text: {:.2f}%\\nRecall score for text: {:.2f}%\".format(accuracy_text*100, f1_score_text*100, precision_text*100, recall_text*100))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy_title, f1_score_title, precision_title, recall_title = svg(X_train_title, y_train_title, X_test_title, y_test_title)\n",
    "print(\"Accuracy for title: {:.2f}%\\nF1 score for title: {:.2f}%\\nPrecision score for title: {:.2f}%\\nRecall score for title: {:.2f}%\".format(accuracy_title*100, f1_score_title*100, precision_title*100, recall_title*100))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Algorithm\n",
    "\n",
    "Using the random forest algorithm (RF) to label between fake and real news.\n",
    "First we are using the text as input afterwards just the titles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test, name, crit='gini'):\n",
    "    rf = RandomForestClassifier(n_estimators = 1000, random_state = 42, verbose=0, n_jobs=-1, criterion=crit)\n",
    "    rf.fit(X_train.tolist(), y_train.tolist())\n",
    "    y_pred = rf.predict(X_test.tolist())\n",
    "    print(\"accuracy for random forest with {} criterion {}: {:.2f}%\".format(crit, name, accuracy_score(y_test.tolist(), y_pred)*100))\n",
    "    print(\"f1 score for random forest with {} criterion{}: {:.2f}%\".format(crit, name, f1_score(y_test.tolist(), y_pred)*100))\n",
    "    print(\"precision score random forest with {} criterion for {}: {:.2f}%\".format(crit, name, precision_score(y_test.tolist(), y_pred)*100))\n",
    "    print(\"recall score for random forest with {} criterion {}: {:.2f}%\".format(crit, name, recall_score(y_test.tolist(), y_pred)*100))\n",
    "\n",
    "\n",
    "random_forest(X_train_text, X_test_text, y_train_text, y_test_text, \"w2v text\")\n",
    "random_forest(X_train_title, X_test_title, y_train_title, y_test_title, \"w2v title\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
